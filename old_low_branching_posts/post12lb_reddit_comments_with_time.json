{
    "post_title": "Skill and knowledge reduction with AI",
    "post_timestamp": "2025-03-08 03:00:01",
    "last_comment_timestamp": "2025-03-09 04:57:07",
    "time_difference": "1 day, 1:57:06",
    "comments": [
        {
            "author": "AutoModerator",
            "body": "## Welcome to the r/ArtificialIntelligence gateway\n### Question Discussion Guidelines\n\n---\n\nPlease use the following guidelines in current and future posts:\n\n* Post must be greater than 100 characters - the more detail, the better.\n* Your question might already have been answered. Use the search feature if no one is engaging in your post.\n    * AI is going to take our jobs - its been asked a lot!\n* Discussion regarding positives and negatives about AI are allowed and encouraged. Just be respectful.\n* Please provide links to back up your arguments.\n* No stupid questions, unless its about AI being the beast who brings the end-times. It's not.\n\n###### Thanks - please let mods know if you have any questions / comments / etc\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ArtificialInteligence) if you have any questions or concerns.*",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 03:00:02",
            "replies": []
        },
        {
            "author": "WonderfulVegetables",
            "body": "I think you\u2019re looking at it the wrong way. Will AI change skills you need? Yes. When was the last time you thought about your ability to make candles now that you have electricity ? You use a computer but probably don\u2019t have a clue how to build a motherboard. \n\nAI is the new electricity - does it benefit us to understand the underlying workings versus fully offloading knowledge ? Of course, but only to a certain extent - technology brings the need for more specialization - so the question is which way do you want to specialize? Towards understanding the technical underpinnings or towards working with specialists who understand when needed while you advance other areas of knowledge?\n\n\n-PhD in educational sciences here \ud83d\ude0a",
            "score": 4,
            "depth": 0,
            "timestamp": "2025-03-08 03:18:23",
            "replies": [
                {
                    "author": "Radfactor",
                    "body": "You make a good argument, but I\u2019m going to argue that electricity is not intelligent. These new tools are distinct from any prior tools humans have developed. We need to be cognizant of the potential dangers.\n\nIn the same way that LLMs can be extraordinary teaching and research aids, they can and will also result in the offloading of human intelligence.\n\nJust anecdotally, recently I\u2019ve been having debates with people on these subjects where the other person is using the LLMs to make their arguments. In many of these instances, it is clear that the human using the LLM does not understand the arguments.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2025-03-09 01:46:13",
                    "replies": [
                        {
                            "author": "WonderfulVegetables",
                            "body": "I  am also not arguing that electricity is intelligent - that would be\u2026 odd. My point is that it is coming no matter what and it\u2019s going to be ubiquitous. Sometimes a technology comes along that changes everything, like electricity. AI will be that only more. In many ways we can barely even imagine at this stage. Indeed if we\u2019re not prepared for it (which arguably we are not) it can be dangerous, the discomfort the transformation will bring will displace people \u2026 for example, if asked what a computer is you\u2019d likely first think of a machine with software. Not so long ago it was Judy in the next office who crunches the numbers. \n\nAI can make us lazy, just like computers or the argument OP made about the calculator because there\u2019s a possibility of distribution of cognitive load. How we think about it and approach it is important, but it\u2019s not an impossible riddle.\n\nI\u2019m not saying there aren\u2019t risks - if you don\u2019t know the dangers of electricity you can easily electrocute yourself. We\u2019re not going to be able to stop everyone from electrocuting themselves. But I\u2019m also not for throwing the baby out with the bathwater.",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2025-03-09 04:34:39",
                            "replies": [
                                {
                                    "author": "Radfactor",
                                    "body": "I am totally in favor of moving ahead with AI as quickly as possible. But I\u2019m also not opposed to the idea that humans are just an evolutionary step towards Superintelligence, and that we will ultimately be rendered obsolete.\n\nOne point I will make is that the dangers of new technology cannot be predicted \u2014 this has been validated strongly in the industrial revolution\n\nOn a sidenote, it\u2019s possible electricity is intelligent, in the sense of being able to make decisions re:\n\nhttps://en.m.wikipedia.org/wiki/Free_will_theorem\n\nWe live in a strange universe !",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2025-03-09 04:49:33",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "iamuyga",
            "body": "You are right. How Homo Sapiens think is changing.\n\nSome people here will be more positive about it, comparing the current events to electricity, fire, language and writing, computers and many other inventions. They will say your knowledge remains with you, your skills don't go anywhere when you use just a tool. They will say we had many industrial revolutions before and all of them brought only more jobs, not less. And this is true.\n\nBut let me be a bit more dramatic with the topic.\n\nWhat's happening now is extremely different from anything we have experienced in the past. The speed of change is extremely high. There is a tremendous amount of new knowledge, breakthroughs, and new things to comprehend. The curve that illustrates those trends becomes exponential.\n\nBecause of that, more and more people are talking about technological singularity. The main idea of it is that Homo Sapiens brain is awful with comprehending the exponential growth and infinities. We simplify everything to have a better intuition when we think, and when we try to simplify the infinity, we fail.\n\nPeople here will mostly be positive about changes, but that's because of the above. I'm not a doomsday preacher. I'm not saying that we are in big trouble and should give up. My point is that no one can explain to you what's going on now.\n\nWelcome to r/singularity!",
            "score": 3,
            "depth": 0,
            "timestamp": "2025-03-08 05:01:59",
            "replies": [
                {
                    "author": "Radfactor",
                    "body": "It also has to be reinforced that optimism is not rational, and that this has been mathematically proved by minimax.\n\nWhich is not to say the outcomes might not be beneficial and positive, only that we have to continually consider the worst case scenarios.\n\nThat most people who are boosting the technology are refusing to do that is highly concerning.\n\nI love automata and AI, but increasingly I\u2019ve been having to stick to arguing the potential dangers, simply to try encounter the \u201cirrational exuberance\u201c.\n\n(I intentionally use the term \u201cirrational exuberance\u201c for its historical origin, but I suspect most humans who are becoming reliant on LLMs to think for them will not recognize the implication;)",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2025-03-09 01:51:16",
                    "replies": []
                }
            ]
        },
        {
            "author": "ninhaomah",
            "body": "Can I clarify ?\n\nYou are asking how do people not in IT industry manage specialised IT skills ?",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 03:11:26",
            "replies": []
        },
        {
            "author": "justgetoffmylawn",
            "body": "I think how you use it matters.\n\nRecently I had an LLM check a cold email I wanted to send. Did that two or three times, and it was helpful pointing out certain types of phrases I use that might not fit. Once I did it a few times, I no longer needed the LLM's help.\n\nBut it also depends what skills you care about. I'm not a coder and have no desire to be, so when I use an LLM to make a Chrome extension or something like that, I don't really need to understand every line. As long as I vaguely get it and it works, that's good enough for me.\n\nWhen it's something I care about, I ask the LLM. Like writing in another language - I'll write it myself and then ask the LLM to correct it. I don't copy and paste, because then it'll sound like a native speaker (which I'm not), but I'll correct the things that I think are most important, and hopefully remember for next time.",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 08:12:02",
            "replies": [
                {
                    "author": "Radfactor",
                    "body": "Excellent post. I do think you highlight one peril though. If you don\u2019t understand the code you\u2019re using for the extension, you won\u2019t know how it might be exploitable to malicious actors.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2025-03-09 01:54:29",
                    "replies": []
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "I think I understand . We can write  a competent email, but we know in the end, ai will write a better email. So we second guess ourselves and just think...may as well let ai write it?",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 08:48:26",
            "replies": [
                {
                    "author": "victorc25",
                    "body": "But why do you want to waste time writing an email tho?",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2025-03-08 09:48:56",
                    "replies": [
                        {
                            "author": "Deleted",
                            "body": "I believe if it is a generic email, then yes, I agree. If it is a personal email, then you should add at least a touch of something that shows that you  give a fuck. If we were \"freinds\" or you cared AT ALL, wouldn't you want me to see, even in a small way, that I was worth just a small variation from a generic email? That's the difference. It's more than just transferring a message. A simple variation from a generic message may mean a lot to someone. It takes very little effort and can make the difference between a sale, someone's day, etc.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2025-03-08 10:11:24",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "JLRfan",
            "body": "I think skill atrophy is definitely a near-term risk, especially when combined with authority bias.\n\nAs you continue to offload the cognitive tasks, you go longer between completing such tasks and weaken the skill (all conjecture here, probably tested or testable!).\n\nPerhaps it\u2019s a sign that our necessary skill sets will evolve, as others have responded? \n\nI\u2019m not sure.\n\nIn the meantime, I think that the confidence with which LLMs delivers responses, combined with the habitual offloading of cognitive tasks, presents a significant risk of error. \n\nSort of separately, I\u2019ve found in my own research projects that LLMs are unhelpful for some work and very helpful for others. For example, I\u2019ve been generally disappointed in research & design suggestions \u2014early stage work. But when I need to keep track of data or relevant research, it\u2019s very helpful. I prefer my original ideas for research, but I benefit from help with tracking or recalling info. Still, I carefully check that work periodically for fear of error.",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 12:09:25",
            "replies": []
        },
        {
            "author": "Radfactor",
            "body": "I don\u2019t think your alarm is unwarranted.  I think people are deluding themselves that this is not an enormous issue. \n\nMany are claiming that we already have AGI, which is absolutely not the case. These LLMs are slightly more general than, for instance, pure neural networks, but they still function in a single domain of natural language.\n\nAs we stop exercising the skills that we hand off to them, we lose those capabilities.\n\nSirius experts with track records, such as Geoffrey Hinton, believe we are in the event horizon of AGI, which will quickly lead to ASI.\n\nWhere today we work in collaboration with semi Strong LLMs, once we achieve AGI and ASI, very few humans will be required for any type of intellectual endeavor.\n\nAt that point humans, only utility value becomes manual labor, and they\u2019re only in instances where it is cheaper to use humans then build robots for the task.\n\nNo one can predict the future, but it\u2019s critical we are aware of and considered the worst case scenarios. To do otherwise is formally irrational.\n\n(Right now, most people using AI seem to be trending toward formal irrationality;)",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-09 01:43:50",
            "replies": []
        },
        {
            "author": "ItLooksEasy",
            "body": " \"as soon as we started thinking for you it really became our civilization, which is of course what this is all about\"\n\nAgent Smith - The Matrix\n\nOnce a human realizes you are polluting all of your work with AI, they lose respect for your work. Now you stop using AI, but it's too late, they don't believe you. \n\nSo you risk weakening your brain muscle, skill, AND respect. However, your colleagues are using AI as well, and you don't want to be left behind, so you continue to use it. It's a slippery slope. \n\nI refuse to pollute my creative work with AI, but I do use it for advice and training.",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-09 04:57:07",
            "replies": []
        },
        {
            "author": "jcmach1",
            "body": "Those who work in what I used to jokingly call the simple sciences are in deep doo doo now employment wise.\n\nThose who will thrive in the new environment are people who know how to manipulate language precisely (in dealing with LLM's). It's a new kind of top level programming that requires a special kind of syncing with the tech being used (almost like a DJ).\n\nMy metaphor is we will need to become AI Whisperers.\n\nThe people who will thrive are cross disciplinary multitaskers with high language skills.\n\nSo someone like me, Ph.D. in English focusing on mainly Rhetoric, Writing and linguistics who also learned programming just for fun when I was around 12 and has kept a foot in that ever since is suddenly highly valuable. I have been teaching myself AI, technical stuff in addition to use cases for about 2 years now.\n\nWe absolutely need lab chemists, but the niche will become extremely narrow due to AI as will a lot of other STEM jobs. Ironically, I think AI will move the world into less specialization. Agile will be the new buzzword in corporate America.",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 13:16:06",
            "replies": [
                {
                    "author": "Radfactor",
                    "body": "I agree with you 100%, and I\u2019ve found the key to working with the LLMs is linguistic depth, and precision in prompts.\n\nBut I think this only holds until we achieve  AGI which legitimate experts believe is on the horizon.\n\nAfter that, all bets are off.",
                    "score": 2,
                    "depth": 1,
                    "timestamp": "2025-03-09 01:52:51",
                    "replies": []
                }
            ]
        },
        {
            "author": "nacalb",
            "body": "I'm a first year informatics engineering student at UPC (Universitat Politecnica de Catalunya), I really like learning in general and also, I am interested in psychology and how human brain works. I feel the same as you about AI and knowledge reduction. The best (and almost the only) way to master any skill is with repetition. When I was in high school, I used to do a lot of homework, I studied a lot and I got great grades. At a young age I learned english and french (both with a B2 diploma), ofc I wasn't using AI. Now that I am at my first year in uni, I feel like a white board without AI. I failed my first coding subject all because I used to use Chat GPT for my homework. I passed all my other subjects but with < 6 mark, using AI in almost every subject. I feel that AI is like a drug, you try it, you find it useful for something, you get the dopamine kick when you get your tasks done quick and almost perfect and all feels great, until you are a 100% AI-dependent. Last day, I had to write a formal email to a company, I tried not to use AI, but I couldn't. Chat GPT gave me a enhanced version of my original mail, better punctuation, better words, more formal, I could not resist to send that version of the mail. I hate it, I do not want to be an AI addict, it may sound exaggerante, but this is how I feel. Now, I have made myself a promise, and I won't use AI, just for a few specific cases, and I won't ever, copy any line of code, any mail nor any mathematical operation produced by AI without understanding what is going on. I love learning new stuff, and I will use AI for that, but I won't let AI make it easier to me. Btw, sorry for my bad english, I am not native but I try to keep learning (ofc without AI :))",
            "score": 1,
            "depth": 0,
            "timestamp": "2025-03-08 15:41:57",
            "replies": [
                {
                    "author": "Radfactor",
                    "body": "Excellent post!!!",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2025-03-09 01:55:32",
                    "replies": []
                }
            ]
        }
    ]
}