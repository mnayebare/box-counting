{
    "post_title": "AI generates covertly racist decisions about people based on their dialect",
    "post_timestamp": "2024-09-02 00:27:09",
    "last_comment_timestamp": "2024-09-24 04:57:20",
    "time_difference": "22 days, 4:30:11",
    "comments": [
        {
            "author": "AutoModerator",
            "body": "Welcome to r/science! This is a heavily moderated subreddit in order to keep the discussion on science. However, we recognize that many people want to discuss how they feel the research relates to their own personal lives, so to give people a space to do that, **personal anecdotes are allowed as responses to this comment**. Any anecdotal comments elsewhere in the discussion will be removed and our [normal comment rules]( https://www.reddit.com/r/science/wiki/rules#wiki_comment_rules) apply to all other comments.\n\n---\n\n**Do you have an academic degree?** We can verify your credentials in order to assign user flair indicating your area of expertise. [Click here to apply](https://www.reddit.com/r/science/wiki/flair/).\n\n---\n\nUser: u/Significant_Tale1705  \nPermalink: https://www.nature.com/articles/s41586-024-07856-5\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/science) if you have any questions or concerns.*",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 00:27:09",
            "replies": []
        },
        {
            "author": "rich1051414",
            "body": "LLM's are nothing but complex multilayered autogenerated biases contained within a black box. They are inherently biased, every decision they make is based on a bias weightings optimized to best predict the data used in it's training. A large language model devoid of assumptions cannot exist, as all it is is assumptions built on top of assumptions.",
            "score": 1996,
            "depth": 0,
            "timestamp": "2024-09-02 00:36:46",
            "replies": [
                {
                    "author": "Chemputer",
                    "body": "So, we're *not* shocked that the black box of biases is biased?",
                    "score": 165,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:20:40",
                    "replies": [
                        {
                            "author": "BlanketParty4",
                            "body": "We are not shocked because AI is the collective wisdom of humanity, including the biases and flaws that come with it.",
                            "score": 41,
                            "depth": 2,
                            "timestamp": "2024-09-02 12:00:37",
                            "replies": [
                                {
                                    "author": "Stickasylum",
                                    "body": "\u201cCollected wisdom\u201d is far too generous, but it certainly has all the flaws and more",
                                    "score": 57,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 13:42:59",
                                    "replies": [
                                        {
                                            "author": "BlanketParty4",
                                            "body": "LLMs are trained on the internet text humanity collectively created. They identify patterns in their training data, which contains both wisdom and flaws of the humanity.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-03 05:54:05",
                                            "replies": [
                                                {
                                                    "author": "Stickasylum",
                                                    "body": "LLMs are trained to model statistical correlations between words, trained on small subsets of the written text of humans (what it most conveniently available). This sometimes produces sequences of words from which can be insightful for humans but also produces sequences of words that lead humans astray, either because it is accurately reproducing sequences reflecting flawed human thoughts, or because the model has produced inaccurate information that looks facially sound to an untrained observer.\n\nAt no point do LLMs model \u201cwisdom\u201d or \u201cknowledge\u201d directly (except when directly programmed to cover flaws), so it\u2019s important to keep in mind that any contained knowledge is purely emergent and only relevant as interpreted by humans.",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-03 12:45:25",
                                                    "replies": [
                                                        {
                                                            "author": "BlanketParty4",
                                                            "body": "Scientific knowledge also comes from analyzing data to find new patterns, just like LLMs. LLMs are trained on large datasets to model statistical relationships between words, creating emergent knowledge similar to how scientists derive insights from data. While LLMs can sometimes produce misleading outputs, this is also true in scientific research when data is misinterpreted. The idea that data can\u2019t generate knowledge ignores how both humans and LLMs extract meaningful information through data analysis.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-03 16:52:42",
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "cyphar",
                                                    "body": "This assumes that human wisdom is entirely contained within the form of text written by a human and that all knowledge is just statistical correlation. I doubt there is any actual evidence that either of those things are true. An AI is fundamentally a compression algorithm that can randomly pick a token based on the compressed data, but I doubt you would argue that zip files \"contain wisdom\".",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-03 10:36:54",
                                                    "replies": [
                                                        {
                                                            "author": "BlanketParty4",
                                                            "body": "Statistical correlation is the core of how humans create scientific knowledge. In many aspects, data driven decisions are superior to human judgement. Also scientifically we don\u2019t need to collect data from the whole population, a representative sample size is sufficient. LLM\u2019s don\u2019t need all written knowledge to be able to identify the patterns, just like we don\u2019t need to know every single person to conduct a cluster analysis. AI doesn\u2019t make predictions randomly, it makes it based on statistical analysis of its training data. In fact, pretty much all we know about the universe are predictions based on the statistical analysis of data.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-03 13:18:52",
                                                            "replies": [
                                                                {
                                                                    "author": "cyphar",
                                                                    "body": "Statistics are used as a tool to expand human knowledge, they are not human knowledge unto themselves.\u00a0\n\n\nMy point was not that LLMs don't have access to all text, my point was that text is simply one of many outputs of the \"human knowledge engine\" -- yeah, you can create a machine that mimics that output but that doesn't mean it has intelligence. The mechanism it uses is basically a compression algorithm, hence the example I used...\n\n\n\nMaybe one day we will actually create AGI, but I don't think it'll come as an evolution of text generation.",
                                                                    "score": 2,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-03 23:30:52",
                                                                    "replies": [
                                                                        {
                                                                            "author": "BlanketParty4",
                                                                            "body": "This is a discussion about what intelligence is. As a data nerd with Aspergers, statistics actually form a crucial part of how I understand the world and I think they play a much deeper role in knowledge creation than you\u2019re giving them credit for. Statistics don\u2019t just expand human knowledge, they help define it. The patterns and correlations we uncover through statistical methods aren\u2019t just a side tool they are foundational to how we make sense of massive amounts of information. In fact, many breakthroughs in science, economics, and even psychology are rooted in statistical models that have pushed our understanding forward. Statistical methods allow us to discover the \u201crules\u201d of the world by showing us relationships we otherwise would not see. Without statistics, our understanding of everything from quantum mechanics to climate science would be severely limited.\n\nAlso LLMs, or machine learning models in general, are not just \u201ccompression algorithms.\u201d They aren\u2019t simply shrinking data down, they are uncovering and leveraging patterns in ways that often surprise us, even as their creators. While it\u2019s true that text is one of many outputs of human intelligence, text is a powerful one, it is how we encode and share much of our knowledge. LLMs, while not intelligent in the human sense, are doing more than compressing this data. They\u2019re drawing inferences and making predictions based on patterns too complex for humans to process alone. So while LLMs are limited, they are more than simple \u201cmimics\u201d, they represent a step toward systems that can perform tasks humans consider \u201cintelligent.\u201d\n\nRegarding AGI, I think you\u2019re underestimating how far text-based systems might take us. Text is not just a passive output, it contains reasoning, problem-solving, and descriptions of cause and effect. By mastering language, these models are slowly inching closer to a form of problem-solving intelligence, even if it doesn\u2019t match human creativity or emotional depth yet. Text-based advancements may very well be part of the AGI journey, especially when integrated with other modalities like vision and action.",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-04 06:22:49",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "cyphar",
                                                                                    "body": "> Without statistics, our understanding of everything from quantum mechanics to climate science would be severely limited.\u00a0\n\n\nThe same is true of algebra, pencils, and water. But none of them by themselves are \"human intelligence\". They're tools.\n\n\nAny paper that uses statistics requires human intuition to interpret the results. Statistics don't give you knowledge or intelligence (nor the answer!), they let you structure information in a way that a human can interpret. Without\u00a0interpretation, statistics are useless.",
                                                                                    "score": 1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-24 04:57:20",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "blind_disparity",
                                    "body": "I think the collective wisdom of humanity is found mostly in peer reviewed scientific articles. This is not that. This is more a distillation of human discourse. The great, the mundane and the trash.\n\nUnfortunately there are some significant problems lurking in the bulk of that, which is the mundane. And it certainly seems to reflect a normal human as a far more flawed and unpleasant being than we like to think of ourselves. I say lurking - the AI reproduces our flaws much more starkly and undeniably.",
                                    "score": 13,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 16:10:44",
                                    "replies": [
                                        {
                                            "author": "BlanketParty4",
                                            "body": "Peer reviewed scientific papers are a very small subset of collective human wisdom, it\u2019s the wisdom of a very small select group. ChatGPT is trained on a very large data set, consisting of social media, websites and books. It has good and the bad in its training. Therefore it\u2019s prone to human biases that are regularly occurring as patterns in its training data.",
                                            "score": 11,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 16:47:35",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "ivietaCool",
                                    "body": "Your knowledge of ai is insufficient for such declarations. You're welcome.",
                                    "score": -9,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 12:22:01",
                                    "replies": [
                                        {
                                            "author": "IcameIsawIclapt",
                                            "body": "They are the sum of the data we feed them. The embeddings between data  and probability of output is highly dependent on data and user input tweaking",
                                            "score": 6,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 13:33:19",
                                            "replies": []
                                        },
                                        {
                                            "author": "Deleted",
                                            "body": "[deleted]",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-04 06:29:35",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "ch4m4njheenga",
                            "body": "Black box of biases and weights is biased and comes with its own baggage.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-02 13:10:24",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "TurboTurtle-",
                    "body": "Right. By the point you tweak the model enough to weed out every bias, you may as well forget neural nets and hard code an AI from scratch... and then it's just your own biases.",
                    "score": 353,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:13:14",
                    "replies": [
                        {
                            "author": "Golda_M",
                            "body": ">By the point you tweak the model enough to weed out every bias\n\nThis misses GP's (correct) point. \"Bias\" is what the model *is.* There is no weeding out biases. Biases are corrected, not removed. Corrected from incorrect bias to correct bias. There is no non-biased.",
                            "score": 240,
                            "depth": 2,
                            "timestamp": "2024-09-02 03:07:49",
                            "replies": [
                                {
                                    "author": "mmoonbelly",
                                    "body": "Why does this remind me of the moment in my research methods course that our lecturer explained that all social research is invalid because it\u2019s impossible to understand and explain completely the internal frames of reference of another culture. \n\n(We were talking about ethnographic research at the time, and the researcher as an outsider)",
                                    "score": 59,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 03:53:26",
                                    "replies": [
                                        {
                                            "author": "gurgelblaster",
                                            "body": "All models are wrong. Some models are useful.",
                                            "score": 120,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 05:03:08",
                                            "replies": [
                                                {
                                                    "author": "TwistedBrother",
                                                    "body": "Pragmatism (via Pierce) enters the chat. \n\nCheck out \u201cFixation of Belief\u201d https://philarchive.org/rec/PEITFO",
                                                    "score": 3,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 12:26:11",
                                                    "replies": []
                                                }
                                            ]
                                        },
                                        {
                                            "author": "WoNc",
                                            "body": "\"Flawed\" seems like a better word here than \"invalid.\" The research may never be perfect, but research could, at least in theory, be ranked according to accuracy, and high accuracy research may be basically correct, despite its flaws.",
                                            "score": 37,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 06:08:10",
                                            "replies": [
                                                {
                                                    "author": "FuujinSama",
                                                    "body": "I think \"invalid\" makes sense if the argument is that ethnographic research should be performed by insiders rather than outsiders. The idea that only someone that was born and fully immersed into a culture can accurately portray that experience. Anything else is like trying to measure colour through a coloured lens.",
                                                    "score": 6,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 06:42:12",
                                                    "replies": [
                                                        {
                                                            "author": "Phyltre",
                                                            "body": "But won't someone from inside the culture also experience the problem in reverse?  Like, from an academic perspective, people are wrong about historical details and importance and so on all the time.  Like, a belief in the War On Christmas isn't what validates such a thing as real.",
                                                            "score": 29,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 08:29:41",
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "grau0wl",
                                                            "body": "And only an ant can accurately portray an ant colony",
                                                            "score": 8,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 06:46:48",
                                                            "replies": [
                                                                {
                                                                    "author": "FuujinSama",
                                                                    "body": "And that's the great tragedy of all Ethology. We'll never truly be able to understand ants. We can only make our best guesses.",
                                                                    "score": 6,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 07:39:07",
                                                                    "replies": []
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "author": "mayorofdumb",
                                            "body": "Comedians get it best \"You know who likes fried chicken a lot? Everybody with taste buds\"",
                                            "score": 8,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 09:44:27",
                                            "replies": []
                                        },
                                        {
                                            "author": "LeiningensAnts",
                                            "body": "> our lecturer explained that all social research is invalid because it\u2019s impossible to understand and explain completely the internal frames of reference of another culture. \n\nThe term for that is \"Irreducible Complexity.\"",
                                            "score": 7,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 05:57:27",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "naughty",
                                    "body": "Bias is operating in two modes in that sentence though. On the one hand we have bias as a mostly value neutral predilection or preference in a direction, and on the other bias as purely negative and unfounded preference or aversion.\n\nThe first kind of biased is inevitable and desirable, the second kind is potentially correctable given a suitable way to measure it.\n\nThe more fundamental issue with removing bias stems from what the models are trained on, which is mostly the writings of people. The models are learning it from us.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 05:30:49",
                                    "replies": [
                                        {
                                            "author": "741BlastOff",
                                            "body": "It's all value-neutral. The AI does not have preferences or aversions. It just has weightings. The value judgment only comes into play when humans observe the results. But you can't correct that kind of bias without also messing with the \"inevitable and desirable\"  kind, because it's all the same stuff under the hood.",
                                            "score": 14,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 06:44:10",
                                            "replies": [
                                                {
                                                    "author": "BrdigeTrlol",
                                                    "body": "I don't think your last statement is inherently true. That's why there are numerous weights and other mechanisms to adjust for unwanted bias and capture wanted bias. That's literally the whole point of making adjustments. To push all results as far in the desired directions as possible and away from undesired ones simultaneously.",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 20:43:17",
                                                    "replies": []
                                                },
                                                {
                                                    "author": "naughty",
                                                    "body": "Them being the same under the hood is why it is sometimes possible to fix it. You essentially train a certain amount then test against a bias you want to remove and fail the training if it fails that test. Models have been stopped from excessive specialisation with these kind of methods for decades.\n\nThe value neutrality is because the models reflect the biases of their training material. That is different from having no values though, not that models can be 'blamed' for their values. They learned them from us.",
                                                    "score": -1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 07:21:24",
                                                    "replies": []
                                                }
                                            ]
                                        },
                                        {
                                            "author": "Bakkster",
                                            "body": ">the second kind is potentially correctable given a suitable way to measure it.\n\nWhich, of course, is the problem. This is near enough to impossible as makes no difference. Especially at the scale LLMs need to work at. Did you really manage to scrub the racial bias out of the entire early 19th century back issues of local news?",
                                            "score": 3,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:10:36",
                                            "replies": [
                                                {
                                                    "author": "Golda_M",
                                                    "body": "They actually seem to be doing quite well at this.\u00a0\n\n\nYou don't need to scrub the bias out of the core source dataset, 19th century\u00a0 local news. You just need labeled (good/bad) examples of \"bias.\"\u00a0 It doesn't have to be definable, consistent or legible definition.\u00a0\n\n\nThe big advantage of how LLMs are constructed, is that it doesn't need rules. Just examples.\u00a0\n\n\nFor (less contentious) corollary, you could train a model to identify \"lame/cool.\" This would embed the subjective biases of the examples... but it doesn't require a legible/objectives definition of cool.\u00a0",
                                                    "score": -1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 11:19:37",
                                                    "replies": [
                                                        {
                                                            "author": "Bakkster",
                                                            "body": ">For (less contentious) corollary, you could train a model to identify \"lame/cool.\" This would embed the subjective biases of the examples... but it doesn't require a legible/objectives definition of cool.\u00a0\n\nRight, it's a problem is scale when you need a billion examples of lame/cool stuff across all the potential corner cases, and avoiding mislabeled content throughout. Not to mention avoiding other training data ending up backdoor undermining that training.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 11:26:26",
                                                            "replies": [
                                                                {
                                                                    "author": "Golda_M",
                                                                    "body": "They're getting good at this.\u00a0\n\n\nEg..\u00a0 early models were often rude or confrontational. Now they aren't.\u00a0",
                                                                    "score": -1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 11:29:55",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Bakkster",
                                                                            "body": "From the abstract: \n\n> Finally, we show that current practices of alleviating racial bias in language models, such as human preference alignment, **exacerbate the discrepancy between covert and overt stereotypes, by superficially obscuring the racism that language models maintain on a deeper level**.\n\nReducing overt racism doesn't necessarily reduce covert racism in the model, and may trick the developers into paying less attention to such covert discrimination.",
                                                                            "score": 3,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 11:39:19",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Golda_M",
                                                                                    "body": "There is no difference between covert and overt. There is only the program's output.\u00a0\n\n\nIf it's identifiable, and a priority, then AIs can be trained to avoid it. Naturally, the most overt aspects were dealt with first.\u00a0\n\n\nBesides that, this is not \"removing bias.\" There is no removing bias. Also, the way that sounds is \"damned if you do, damned if you don't.\"\n\n\nAlleviating obvious, offensive to most \"biases\" exacerbates the problem. Why? Because it hides how biased they \"really\" are.\u00a0\n\n\nThis part is pure fodder.\u00a0",
                                                                                    "score": -1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 11:47:56",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Bakkster",
                                                                                            "body": ">There is no difference between covert and overt. \n\nThis isn't what the study says.\n\n>There is only the program's output.\u00a0\n\nThey're both program outputs, but categorized differently because humans treat them differently. \n\nIt's immediately obvious that an LLM dripping the n-word is bad. It's overt. It's less apparent whether asking for the LLM to respond \"like a criminal\" and getting AAVE output is a result of harmful racial bias in the model, especially to a user who doesn't know if they're the only person who gets this output or if it's overrepresented.\n\n>If it's identifiable, and a priority, then AIs can be trained to avoid it. Naturally, the most overt aspects were dealt with first.\u00a0\n\nTo be clear, this is the concern, that developers either won't notice or won't prioritize the more subtle covert racism.",
                                                                                            "score": 1,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 11:55:36",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "Golda_M",
                                                                                                    "body": "I don't see how this is a meaningful statement.\u00a0 It's intentionally imprecise use of language that doesn't describe the data they are observing, imo.\u00a0\n\n\nIf overt/covert just means degrees of severity, then yes. Developers will not prioritize low severity over high severity... most likely.\n\n\nThat said, pleasing to us-centric researchers of ai bias... is a very high priority since day one. I doubt any specific attention will be given to the cultural preferences of other countries and languages.\u00a0",
                                                                                                    "score": 1,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 12:12:22",
                                                                                                    "replies": []
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "author": "Golda_M",
                                            "body": ">Bias is operating in two modes in that sentence though. On the one hand we have bias as a mostly value neutral predilection or preference in a direction, and on the other bias as purely negative and unfounded preference or aversion.\n\nThese are not distinct phenomenon. It's can only be \"value neutral\" relative to a set of values. \n\nFrom a software development perspective, there's no need to distinguish between bias A & B. As you say, A is desirable and normal. Meanwhile, \"B\" isn't a single attribute called bad bias. It's two unrelated attributes: unfounded/untrue and negative/objectionable. \n\nUnfounded/untrue is a big, general problem. Accuracy. The biggest driver of progress here is pure power. Bigger models. More compute. Negative/objectionable is, from the LLMs perspective, arbitrary. It's not going to improve with more compute. So instead, developers use synthetic datasets to teach the model \"right from wrong.\" \n\nWhat is actually going on, in terms of engineering, is injecting intentional bias. Where that goes will be interesting. I would be interested in seeing if future models exceed the scope of intentional bias or remain confined to it.  \n\nFor example, if we remove dialect-class bias in British contexts... conforming to British standards on harmful bias... how does that affect non-english output about Nigeria? Does the bias transfer, and how.",
                                            "score": 5,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:02:54",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "ObjectPretty",
                                    "body": "\"correct\" biases.",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2024-09-03 07:45:16",
                                    "replies": [
                                        {
                                            "author": "Golda_M",
                                            "body": "Look... IDK if we can clean up the language we use, make it more precise and objective. I don't even know that we should. \n\nHowever... the meaning and implication of \"bias\" in casual conversation, law/politics, philosophy and AI or software engineering.... They cannot be the same thing, and they aren't.\n\nSo... we just have to be aware of these differences. Not the precise deltas, just the existence of difference.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-03 07:59:14",
                                            "replies": [
                                                {
                                                    "author": "ObjectPretty",
                                                    "body": "Oh, this wasn't a comment on your explanation which I thought was good.\n\nWhat I wanted to express was skepticism towards humans being unbiased enough to be able to \"correct\" the bias in an LLM.",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-03 19:39:48",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Crypt0Nihilist",
                                    "body": "I've started to enjoy watching someone pale and look a little sick then I tell a layman that there is no such thing as an unbiased model, only one that conforms to their biases.",
                                    "score": 0,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 08:15:50",
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "Liesmith424",
                            "body": "It turns out that ChatGPT is just a single 200 petabyte switch statement.",
                            "score": 14,
                            "depth": 2,
                            "timestamp": "2024-09-02 06:07:06",
                            "replies": []
                        },
                        {
                            "author": "Ciff_",
                            "body": "No. But it is also pretty much impossible. If you exclude theese biases completly your model will perform less accurately as we have seen.",
                            "score": 27,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:36:56",
                            "replies": [
                                {
                                    "author": "TurboTurtle-",
                                    "body": "Why is that? I'm curious.",
                                    "score": 4,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:06:03",
                                    "replies": [
                                        {
                                            "author": "Ciff_",
                                            "body": "Your goal of the model is to give as accurate information as possible. If you ask it to describe an average European the most accurate description would be a white human. If you ask it do describe the average doctor a male. And so on. It is correct, but it is also not what we want. We have examples where compensating this has gone hilariously wrong where asked for a picture of the founding fathers of America it included a black man https://www.google.com/amp/s/www.bbc.com/news/technology-68412620.amp\n\nIt is difficult if not impossible to train the LLM to \"understand\" that when asking for a picture of a doctor gender does not matter, but when asking for a picture of the founding fathers it *does* matter. One is not more or less of a fact than the other according to the LLM/training data.*",
                                            "score": 59,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 02:12:52",
                                            "replies": [
                                                {
                                                    "author": "GepardenK",
                                                    "body": "I'd go one step further. Bias is the mechanism by which you can make predictions in the first place. There is no such thing as eliminating bias from a predictive model, that is an oxymoron. \n\nAll you can strive for is make the model abide by some standard that we deem acceptable. Which, in essence, means having it comply with our bias towards what biases we consider moral or productive.",
                                                    "score": 68,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 02:18:05",
                                                    "replies": [
                                                        {
                                                            "author": "rich1051414",
                                                            "body": "This is exactly what I was getting at. All of the weights in a large language models are biases that are self optimized. You cannot have no bias while also having an LLM. You would need something fundamentally different.",
                                                            "score": 34,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 02:23:21",
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "FjorgVanDerPlorg",
                                                            "body": "Yeah there are quite a few aspects of these things that provide positive and negatives at the same time, just like there is with us.\n\nI think the best example would be Temperature type parameters, which you quickly discover trade creativity and bullshitting/hallucination, with rigidness and predictability. So it becomes equations like ability to be creative also increases ability to hallucinate and only one of those is highly desirable, but at the same time the model works better with it than without.",
                                                            "score": 6,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 03:06:36",
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "Morthra",
                                                    "body": "> We have examples where compensating this has gone hilariously wrong where asked for a picture of the founding fathers of America it included a black man\n\nThat happened because there was a *second* AI that would modify user prompts to inject diversity into them. So for example, if you asked Google's AI to produce an image with the following prompt:\n\n> \"Create an image of the Founding Fathers.\"\n\nIt would secretly be modified to instead be\n\n> \"Create me a diverse image of the Founding Fathers\"\n\nOr something to that effect. Google's AI would then take this modified prompt and work accordingly.\n\n> It is difficult if not impossible to train the LLM to \"understand\" that when asking for a picture of a doctor gender does not matter, but when asking for a picture of the founding fathers it does matter. One is not more or less of a fact than the other according to the LLM/training data.*\n\nAnd yet Google's AI would outright *refuse* to generate pictures of white people. That was deliberate and intentional, not a bug because it was a hardcoded rule that the LLM was given. If you gave it a prompt like \"generate me a picture of a white person\" it would return a \"I can't generate this because it's a prompt based on race or gender\", but it would only do this if the race in question was \"white\" or \"light skinned.\"\n\nMost LLMs have been deliberately required to have certain political views. It's *extremely* overt, and anyone with eyes knows what companies like Google and OpenAI are doing.",
                                                    "score": 22,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 05:12:47",
                                                    "replies": []
                                                },
                                                {
                                                    "author": "FuujinSama",
                                                    "body": "I think this is an inherent limitation of LLMs. In the end, they can recite the definition of gender but they don't *understand* gender. They can solve problems but they don't *understand* the problems they're solving. They're just making probabilistic inferences that use a tremendous ammount of compute power to bypass the need for full understanding.\n\nThe hard part is that defining \"true understanding\" is hard af and people love to make an argument that if something is hard to define using natural language it is ill-defined. But every human on the planet knows what they mean by \"true understanding\", it's just an hard concept to model accurately. Much like every human understands what the colour \"red\" is, but trying to explain it to a blind person would be impossible.\n\nMy best attempt to distinguish LLMs inferences from true understanding is the following: LLMs base their predictions on *knowing* the probability density function of the multi-dimensional search space with high certainty. They know the density function so well (because of their insane memory and compute power) that they can achieve remarkable results. \n\nTrue understanding is based on congruent modelling. Instead of learning the PDF exhaustively through brute force, true understanding implies running logical inference through every single prediction done through the PDF, and rejecting the inferences that are not congruent with the majority consensus. This, in essence, builds a full map of \"facts\" which are self-congruent on a given subject (obviously humans are biased and have incongruent beliefs about things they don't truly understand). New information gained is then judged based on how it fits the current model. A large degree of new data is needed to overrule consensus and remodel the Map. (I hope my point that an LLM makes no distinction between unlikely and incongruent. I know female fathers can be valid but transgender parenthood is a bit out of topic.) \n\nIt also makes no distinction between fact, hypothetical or fiction. This is connected. Because the difference between them is in logical congruence itself. If something is an historical fact? It is what it is. The likelihood matters only in so much as one's trying to derive the truth from many differing accounts. A white female Barack Obama is pure non-sense. It's incongruent. White Female is not just unlikely to come next to Barack Obama, it goes against the definition of Barack Obama.\n\nHowever, when asked to generate a random doctor? That's an hypothetical. The likelihood of the doctor shouldn't matter. Only the things inherent to the word \"doctor\". But the machine doesn't understand the difference between \"treats people\" and \"male, white and wealthy\" they're just all concepts that usually accompany the word \"doctor\". \n\nIt gets even harder with fiction. Because fictional characters are not real, but they're still restricted. Harry Potter is an heterosexual white male with glasses and a lightning scar that shoots lightning. Yet, if you search the internet far and wide you'll find that he might be gay. He might also be bi. Surely he can be the boyfriend of every single fanfiction writer's self inset at the same time! Yet, to someone that truly understand the concept of Harry Potter, and the concept of Fan Fiction? That's not problematic at all? To an LLM? Who knows!\n\nNow, current LLMs won't make many of these sort of basic mistakes because the data they're not trained that naively *and* they're trained on so much data that correctness becomes more likely simply because there are many ways to be wrong but only a single way to be correct . But the core architecture is prone to this sorts of mistakes and does not inherently encompass logical congurence between concepts.",
                                                    "score": 6,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 07:19:59",
                                                    "replies": [
                                                        {
                                                            "author": "Fair-Description-711",
                                                            "body": "> But every human on the planet knows what they mean by \"true understanding\", it's just an hard concept to model accurately.\n\nThis is an \"argument from collective incredulity\".\n\nIt's a hard concept because we ourselves don't sufficiently understand what it means to understand something down to some epistemically valid root.\n\nHumans certainly have a built in sense of whether they understand things or not. But we also know that this sense of \"I understand this\" can be fooled.\n\nIndeed our \"I understand this\" mechanism seems to be a pretty simple heuristic--and I'd bet it's roughly the same heuristic LLMs use, which is roughly \"am I frequntly mispredicting in this domain?\".\n\nYou need only engage with a few random humans on random subjects you have a lot of evidence you understand well to see that they clearly *do not* understand many things they are extremely confident they do understand.\n\nLLMs are certainly handicapped by being so far removed from what we think of as the \"real world\", and thus have to infer the \"rules of reality\" from the tokens that we feed them, but I don't think they're as handicapped by insufficient access to \"understanding\" as you suggest.",
                                                            "score": 2,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 12:52:40",
                                                            "replies": [
                                                                {
                                                                    "author": "FuujinSama",
                                                                    "body": "> This is an \"argument from collective incredulity\".\n\nI don't think it is. I'm not arguing that something is true because it's hard to imagine it being false. I'm arguing it is true because it's easy to imagine it's true. If anything, I'm making an argument from intuition. Which is about the opposite of an argument from incredulity.\n\nSome point to appeals to intuition as a fallacy, but the truth is that causality itself is nothing more than an intuition. So I'd say following intuition unless there's a clear argument against intuition is the most sensible course of action. The idea that LLMs must learn the exact same way as humans *because* we can't imagine a way in which they could be different? Now that is an argument from incredulity! There's infinite ways in which they could be different but only one in which it would be the same. Occam's Razor tells me that unless there's very good proof they're the exact same, it's much safer to bet that there's something different. Specially when my intuition *agrees*.\n\n>Indeed our \"I understand this\" mechanism seems to be a pretty simple heuristic--and I'd bet it's roughly the same heuristic LLMs use, which is roughly \"am I frequntly mispredicting in this domain?\".\n\nI don't think this is the heuristic at all. When someone tells you that Barack Obama is a woman you don't try to extrapolate a world where Barack Obama is a woman and figure out that world is improbable. You just go \"I know Barack Obama is a man, hence he can't be a woman.\" There's a prediction bypass for incongruent ideas. \n\nIf I were to analyse the topology of human understanding, I'd say the base building blocks are *concepts* and these concepts are connected not by quantitative links but by specific and discrete *linking* concepts. The concept of \"Barack Obama\" and \"Man\" are connected through the \"definitional fact\" linking concept. And the concept of \"Man\" and \"Woman\" are linked by the \"mutually exclusive\" concept (ugh, again, *not really*, I hope NBs understand my point). So when we attempt to link \"Barack Obama\" to two concepts that are linked as mutually exclusive, our brain goes \"NOOOO!\" and we refuse to believe it without far more information.\n\nObservational probabilities are thus not a fundamental aspect of how we understand the world and make predictions, but just one of many ways we establish this concept linking framework. Which is why we can easily learn concepts *without* repetition. If a new piece of information is congruent with the current conceptual modelling of the world, we will readily accept it as fact after hearing it a single time.\n\nProbabilities are by far not the only thing, though. Probably *because* everything needs to remain consistent. So you can spend decades looking at a flat plain and thinking \"the world is flat!\" but then someone shows you a boat going over the horizon and... the idea that the world is flat is now incongruent with the idea that the sail is the last thing to vanish. A single observation and it now has far more impact than an enormous number of observations where the earth appears to be flat. Why? Because the new piece of knowledge comes with a *logical demonstration* that your first belief was wrong. \n\nThis doesn't mean humans are not going to understand wrong things. If the same human had actually made a ton of relationships based on his belief that the earth was flat and had written fifty scientific articles that assume the earth his flat and don't make sense otherwise? That person will become incredibly mad, then they'll attempt to delude themselves. They'll try to find any possible logical explanation that keeps their world view. But the fact that there will be a *problem* is obvious. Human intelligence is incredible at keeping linked beliefs *congruent*. \n\nThe conceptual links themselves are also quite often wrong themselves, leading to entirely distorted world views! And those are just as hard to tear apart as soundly constructed world views. \n\nLLMs and all modern neural networks are far simpler. Concepts are not inherently different. \"Truth\" \"eadible\" and \"Mutually Exclusive\" are not distinct from \"car\" \"food\" or \"poison\". They're just quantifiably linked through the probability of appearing in a certain order in sentences. I also don't think such organization would spontaneously arise from just training an LLM with more and more data. Not while the only heuristic at play is producing text that's congruent with the PDF restricted by a question with a certain degree of allowable deviasion given by a temperature factor.",
                                                                    "score": 2,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 14:25:46",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Fair-Description-711",
                                                                            "body": "> When someone tells you that Barack Obama is a woman you don't try to extrapolate a world where Barack Obama is a woman and figure out that world is improbable. \n\nSure you do. You, personally, just don't apply the \"prediction\" label to it.\n\n> You just go \"I know Barack Obama is a man, hence he can't be a woman.\"\n\nOr, in other words, \"my confidence in my prediction that Obama has qualities that firmy place him in the 'man' category is very, very high, and don't feel any need to spend effort updating that belief based on the very weak evidence of someone saying he's a woman\".\n\nBut, if you woke up, and everyone around you believed Obama was a woman, you looked up wikipedia and it said he was a woman, and you met him in person and he had breasts and other female sexual characteristics, etc, etc, you'd eventually update your beliefs, likely adding in an \"I had a psychotic episode\" or something.\n\nYou don't \"know\" it in the sense of unchanging information, you believe it with high confidence.\n\n> The concept of \"Barack Obama\" and \"Man\" are connected through the \"definitional fact\" linking concept. \n\nThat's not how my mind works, at least regarding that fact, and I doubt yours really does either since you mention that more information might change your mind--how could more information change a \"definitional fact\"?\n\nI have noticed many humans can't contemplate counterfactuals to certain deeply held beliefs, or can't understand that our language categories are ones that help us but do not (at least usually) capture some kind of unchangable essence--for example, explaining the concept of \"nonbinary\" folks to such people is very, very hard, because they wind up asking \"but he's a man, right?\"\n\nYoung children arguing with each other do this all the time--they reason based on categories because they don't really understand the that it's a category and not a definitional part of the universe.\n\nI suspect [E-Prime](https://en.wikipedia.org/wiki/E-Prime) is primarily helpful because it avoids this specific problem in thinking (where categories are given first-class status in understanding the world).\n\n> Which is why we can easily learn concepts without repetition.\n\nYeah, LLMs definitely [never do that](https://www.fast.ai/posts/2023-09-04-learning-jumps/). ;)\n\n> Because the new piece of knowledge comes with a logical demonstration that your first belief was wrong.\n\nOr in other words, because your prior predictions were shown to not correspond to other even higher-confidence predictions such as \"there's a world and my sight reflects what's happening in the world\", you update your prediction.\n\nIf someone else came by and said \"no, that's just an optical illusion\", and demonstrated a method to cause that optical illusion, you might reaonably reduce your confidence in a round Earth.\n\n> LLMs and all modern neural networks are far simpler.\n\nAre they? How is it you have knowledge of whether concepts exist in LLMs?\n\n> [In LLMs,] Concepts are not inherently different.\n\nAnd you know this because...? (If you're going to say something about weights and biases not having the structure of those concepts, can you point at human neurons and show such structure?)\n\n> \"Truth\" \"eadible\" and \"Mutually Exclusive\" are not distinct from \"car\" \"food\" or \"poison\"\n\nI can't find any way to interpret this that isn't obviously untrue, can you clarify?\n\n> I also don't think such organization would spontaneously arise from just training an LLM with more and more data.\n\nWhy not?\n\nThey seem to spontaneously arise in humans when you feed them more and more world data.",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 17:08:47",
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "blind_disparity",
                                                    "body": "Which nicely highlight why LLMs are good chatbots, and good Google search addons, but bad oracles of wisdom and truth and leaders of humanity into the glorious future where we will know the perfect and ultimately best answer to any factual or moral question.",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 16:16:38",
                                                    "replies": []
                                                },
                                                {
                                                    "author": "svefnugr",
                                                    "body": "Why is it not what we want? Don't we want objective answers?",
                                                    "score": 2,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 04:22:06",
                                                    "replies": [
                                                        {
                                                            "author": "Ciff_",
                                                            "body": "That is a philosophical answer. If you ask someone to decribe a doctor, neither male or female is right or wrong.  Thing is, LLMs does what is statisticaly probable - that is however not what is relevant for the many every day uses of an LLM. If I ask you to describe a doctor I am not asking \"what is the most probable characteristics of a doctor\", I expect you to sort that information to the relevant pieces such as \"works in a hospital\" , \" diagnoses and helps humans\" etc. Not for you to say \"typically male\" as that is by most regarded as completly irrelevant. However if I ask you to describe doctor John Doe, I do expect you to say it's a male. LLMs generally can't make this distinction. In this regard it is not useful what is \"objectively right\" or \"statistically correct\". We are not asking a 1+1 question.",
                                                            "score": 12,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 04:26:49",
                                                            "replies": [
                                                                {
                                                                    "author": "Drachasor",
                                                                    "body": "You're assuming it's statistically based on reality when it's not.\u00a0 It's statistically based on writing, which is a very different thing.\u00a0 That's why they have such a problem with racism and sexism in the models and that can't rid of it.",
                                                                    "score": 4,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 05:43:17",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Ciff_",
                                                                            "body": "It is statisticaly based on the training data. Which can be writing. Or it can be multi modal based with transformers using sounds, pictures, etc.",
                                                                            "score": 8,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 06:05:56",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Drachasor",
                                                                                    "body": "But the important point is that the training data does not always align with objective reality.\u00a0 Hence, things like racism or sexism getting into the model.\u00a0 And it's proven impossible to get rid of these. And that's a problem with you want the model to be accurate instead of just repeating bigotry and nonsense.\u00a0 This is probably something they'll never fix about LLMs.\n\n\n\nBut it's also true that the model isn't really a perfect statistical representation of the training data either, since more work is done to the model beyond just the data.",
                                                                                    "score": 1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 08:06:38",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Ciff_",
                                                                                            "body": "In a sense it ironically decently represents reality since it perputrates bigotry and sexisms from it's training data that in turn is usually a pretty big sample of human thought. Not sure it is helpful to speak in terms of objective reality. We know we don't want theese characteristics, but we have a hard time not seeing them as the data we have contains them.",
                                                                                            "score": 2,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 08:09:51",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "Drachasor",
                                                                                                    "body": "We have plenty of examples of LLMs producing bigotry that's just known to not be true.\u00a0\n\n\nLet's take the doctor example, an example given was asking for a 'typical' doctor (which frankly, varies from country to county and even specialization), you can remove the typical and they'll act like it's all white men. It certainly doesn't reflect that about 1/3 of doctors are women (and this is growing) or how many are minorities.\u00a0 It's not like 33%+ of the time the doctor will be a woman.\u00a0 So even in this, it's just producing bigoted output.\u00a0 We can certainly talk about objective reality here.\u00a0\n\n\nLet's remember that without special training beyond the training data, these systems will produce all kinds of horrifically bigoted output such as objectively incorrect claims about intelligence, superiority, etc, etc.\u00a0 Or characterizing \"greedy bankers\" as Jewish.\u00a0 Tons of other examples.\u00a0 We can absolutely talk about objective reality here and how this is counter to it.\u00a0 It's also not desirable or useful for general use (at best only possibly useful for studying bigotry).\n\n\n\nAnd OpenAI has even published that the bigotry cannot be completely removed from the system.\u00a0 That's why there are studies looking at how it still turns up.\u00a0 It's also why these systems should not be used to make decisions about real people.",
                                                                                                    "score": 0,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 08:23:14",
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "741BlastOff",
                                                                                                            "body": "\"Greedy bankers\" is definitely an example of bigoted input producing bigoted output. But 2/3 of doctors being male is not, in that case the training data reflects objective reality, thus so does the AI. Why would you expect it to change its mind 33% of the time? In every instance it finds the statistically more probable scenario.",
                                                                                                            "score": 2,
                                                                                                            "depth": 12,
                                                                                                            "timestamp": "2024-09-02 08:34:48",
                                                                                                            "replies": [
                                                                                                                {
                                                                                                                    "author": "Drachasor",
                                                                                                                    "body": "No, you missed my point.\u00a0 It won't act like doctors aren't men 1/3 of the time. Reflecting reality would mean acting like there's a significant number of doctors that are women or not white.\n\n\nI'm not sure how you can say that output that ignores the real diversity is accurate or desirable.\n\n\nAnd again, that statistic isn't even true for every country.\u00a0 In some, more women are doctors.\u00a0 And it's not going to be true over time either.\n\n\nIn all these and many other ways, it's not desirable\u00a0behavior.",
                                                                                                                    "score": 1,
                                                                                                                    "depth": 13,
                                                                                                                    "timestamp": "2024-09-02 08:42:50",
                                                                                                                    "replies": []
                                                                                                                }
                                                                                                            ]
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                },
                                                                {
                                                                    "author": "svefnugr",
                                                                    "body": "But what you're describing are not probable characteristics of a doctor, it's the definition of a doctor. That's different.",
                                                                    "score": 1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-03 09:02:43",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Ciff_",
                                                                            "body": "And how does that in any way matter in terms of an LLM?",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-03 09:04:30",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "svefnugr",
                                                                                    "body": "It very much does because it's answering the question you wrote, not the question you had in mind.",
                                                                                    "score": 1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-05 09:31:24",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                },
                                                                {
                                                                    "author": "LeiningensAnts",
                                                                    "body": "What is a doctorate?",
                                                                    "score": -1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 06:55:39",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Ciff_",
                                                                            "body": "\"Typically male\"",
                                                                            "score": 0,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 06:58:28",
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "author": "Zoesan",
                                                            "body": "What is an objective answer to a subjective question?",
                                                            "score": 8,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 04:58:58",
                                                            "replies": [
                                                                {
                                                                    "author": "svefnugr",
                                                                    "body": "\"What is the more probable gender of a doctor\" is not a subjective question.",
                                                                    "score": 1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-03 08:59:45",
                                                                    "replies": []
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "GeneralMuffins",
                                                    "body": "This just sounds like it needs more RLHF, there isn\u2019t any indication that this would be impossible.",
                                                    "score": -1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 02:58:11",
                                                    "replies": [
                                                        {
                                                            "author": "Ciff_",
                                                            "body": "That is exactly what they tried. Humans can't train the LLM to distinguish between theese scenarios. They can't categorise every instance of \"fact\" vs \"non-fact\". It is infeasible. And even if you did you just get an overfitted model. So far we have been unable to have humans (who of course are biased aswell) successfully train LLMs to distinguish between theese scenarios.",
                                                            "score": 11,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 03:01:19",
                                                            "replies": [
                                                                {
                                                                    "author": "GeneralMuffins",
                                                                    "body": "If humans are able to be trained to distinguish such scenarios I don\u2019t see why LLM/MMMs wouldn\u2019t be able to given the same amount of training.",
                                                                    "score": -7,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 03:03:30",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Ciff_",
                                                                            "body": "I don't see how thoose correlate, LLMs and humans function fundamentally different. Just because humans has been trained this way does not mean the LLM can adopt the same biases. There are restrictions in the fundamentals of LLMs that may or may not apply. We simply do not know. \n\nIt may be theoretically possible to train LLMs to have the same bias as an expert group of humans, where it can distinguish where it should apply bias to the data and where it should not. We simply do not know. We have yet to prove that it is theoretically possible. And then it has to be *practically* possible - it may very well not be.\n\nWe have made many attempts - so far we have not seen any success.",
                                                                            "score": 9,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 03:15:25",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "GeneralMuffins",
                                                                                    "body": "We have absolutely no certainty on how human cognition functions. Though we do have an idea how individual neurons work in isolation and in that respect both can be abstractly considered bias machines.",
                                                                                    "score": -3,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 03:19:17",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Ciff_",
                                                                                            "body": "It is a false assumption to say that because it works in humans it can work in LLMs. That is sometimes true, but in no way do we know that it always holds true - likely it does not.",
                                                                                            "score": 4,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 03:20:27",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "GeneralMuffins",
                                                                                                    "body": "You understand that you are falling victim to such false assumptions right? \n\nModels are objectively getting better in the scenarios you mentioned with more RLHF, certainly we can quantitatively measure that SOTA LLM/MMM models don\u2019t fall victim to them anymore. Thus the conclusion that its impossible to train models to not to produce such erroneous interpretations appears flawed.",
                                                                                                    "score": 1,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 03:27:13",
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "Ciff_",
                                                                                                            "body": ">You understand that you are falling victim to such false assumptions right? \n\nExplain. I have said *we do not know* if it is possible. You said\n\n> If humans are able to be trained to distinguish such scenarios I don\u2019t see why LLM/MMMs wouldn\u2019t be able to\n\nThat is a bold false assumption. Just because humans can be trained does not imply an LLM can be*.",
                                                                                                            "score": 2,
                                                                                                            "depth": 12,
                                                                                                            "timestamp": "2024-09-02 03:28:34",
                                                                                                            "replies": [
                                                                                                                {
                                                                                                                    "author": "GeneralMuffins",
                                                                                                                    "body": "If we do not know it is possible why are we making such absolute conclusions?\n\nGiven we already know that more RLHF improves models in such scenario we can say with confidence the conclusion you are making is likely a false assumption.",
                                                                                                                    "score": 1,
                                                                                                                    "depth": 13,
                                                                                                                    "timestamp": "2024-09-02 03:32:09",
                                                                                                                    "replies": [
                                                                                                                        {
                                                                                                                            "author": "Ciff_",
                                                                                                                            "body": "What we know is:\n\n- It is hard\n- We have yet to even remotely succeed\n- The methodologies and strategies applied so far has not been succesfull. Here I think you give too much credit to RLHF attempts.\n- We don't know if it is possible\n\nYou are again saying I make conclusions, but you cannot say what you think is the false assumption? I have not said that it is impossible, I have said that it is hard, it *may* be impossible, and we have yet to succeed.\n\n*Yet you are saying since humans can, LLMs can, that is if anything a false assumption.",
                                                                                                                            "score": 2,
                                                                                                                            "depth": 14,
                                                                                                                            "timestamp": "2024-09-02 03:35:11",
                                                                                                                            "replies": [
                                                                                                                                {
                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                    "body": "Im super confused about your conclusion that current methodologies and strategies have been unsuccessful given SOTA models no longer fall victim to the scenarios you outline. Does that not give some indication that perhaps your assumptions lean on being false?",
                                                                                                                                    "score": 1,
                                                                                                                                    "depth": 15,
                                                                                                                                    "timestamp": "2024-09-02 03:37:58",
                                                                                                                                    "replies": [
                                                                                                                                        {
                                                                                                                                            "author": "Ciff_",
                                                                                                                                            "body": "I'm sorry but I am not sure you know what the SOTA LLM evaluation model is if you are using it as a foundation for your argument that we have begun to solve the LLM bias issue.\n\nEdit: here we have a pretty good paper on the current state of affairs? https://arxiv.org/html/2405.01724v1",
                                                                                                                                            "score": 0,
                                                                                                                                            "depth": 16,
                                                                                                                                            "timestamp": "2024-09-02 03:40:59",
                                                                                                                                            "replies": [
                                                                                                                                                {
                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                    "body": "Neither do you or the researchers as the evaluation model hasn\u2019t been made publicly available for SOTA models thus quantitative analysis is the only way we can measure bias and in this regard SOTA models are undeniably improving with more RLHF, indeed the scenarios you outline as examples no longer are issues seen in the latest SOTA LLM/MMM iterations",
                                                                                                                                                    "score": 1,
                                                                                                                                                    "depth": 17,
                                                                                                                                                    "timestamp": "2024-09-02 03:44:07",
                                                                                                                                                    "replies": [
                                                                                                                                                        {
                                                                                                                                                            "author": "Ciff_",
                                                                                                                                                            "body": "I'm checking out. I have classified you as not knowing what you are talking about. Your response makes *no sense*.",
                                                                                                                                                            "score": 2,
                                                                                                                                                            "depth": 18,
                                                                                                                                                            "timestamp": "2024-09-02 03:48:12",
                                                                                                                                                            "replies": [
                                                                                                                                                                {
                                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                                    "body": "Convenient that isn\u2019t it.",
                                                                                                                                                                    "score": 0,
                                                                                                                                                                    "depth": 19,
                                                                                                                                                                    "timestamp": "2024-09-02 03:49:46",
                                                                                                                                                                    "replies": [
                                                                                                                                                                        {
                                                                                                                                                                            "author": "Ciff_",
                                                                                                                                                                            "body": "Rather quite unconvinient. In this light the whole discussion is pretty useless.",
                                                                                                                                                                            "score": 2,
                                                                                                                                                                            "depth": 20,
                                                                                                                                                                            "timestamp": "2024-09-02 03:51:07",
                                                                                                                                                                            "replies": [
                                                                                                                                                                                {
                                                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                                                    "body": "If we can\u2019t even agree on the facts then yes good faith discussion is useless",
                                                                                                                                                                                    "score": 1,
                                                                                                                                                                                    "depth": 21,
                                                                                                                                                                                    "timestamp": "2024-09-02 03:51:53",
                                                                                                                                                                                    "replies": []
                                                                                                                                                                                }
                                                                                                                                                                            ]
                                                                                                                                                                        }
                                                                                                                                                                    ]
                                                                                                                                                                }
                                                                                                                                                            ]
                                                                                                                                                        }
                                                                                                                                                    ]
                                                                                                                                                }
                                                                                                                                            ]
                                                                                                                                        }
                                                                                                                                    ]
                                                                                                                                }
                                                                                                                            ]
                                                                                                                        }
                                                                                                                    ]
                                                                                                                }
                                                                                                            ]
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        },
                                                                        {
                                                                            "author": "monkeedude1212",
                                                                            "body": "It comes down to the fundamental of understanding the meaning of words vs just seeing relationships between words.\n\nYour phone keyboard can help predict the next word sometimes, but it doesn't know what those words mean. Which is why enough next word auto suggestions in a row don't make fully coherent sentences. \n\nIf I tell you to picture a black US president, you might picture Barrack Obama, or Kamala Harris, or Danny Glover, but probably not Chris Rock \n\nThere's logic and reason you might pick each. \n\nBut you can't just easily train an AI on \"What's real or not\".\n\nMy question didn't ask for reality. But one definitely has been president. Another could be in the future, but deviates heavily on gender from other presidents. And the third one is an actor who played a president in a movie; a fiction that we made real via film, or a reality made fiction, whichever way to spin that. While the last one is an actor that hasn't played the president (to my knowledge) - but we could all imagine it.\n\nWhat behavior we want from an LLM will create a bias in a way that doesn't always make sense in every possible scenario. Even a basic question like this can't really be tuned for a perfect answer.",
                                                                            "score": 4,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 03:44:59",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "GeneralMuffins",
                                                                                    "body": "What does it mean to \u201cunderstand\u201d? Answer that question and you\u2019d be well on your way to receiving a nobel prize",
                                                                                    "score": 2,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 03:46:20",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "monkeedude1212",
                                                                                            "body": "It's obviously very difficult to quantify a whole and explicit definition, much like consciousness. \n\nBut we can know when things aren't conscious, just as we can know when someone doesn't understand something. \n\nAnd we know how LLM work well enough (they can be a bit of a black box but we understand how they work, which is why we can build them) - to know that a LLM doesn't understand the things it says. \n\nYou can tell chatGPT to convert some feet to meters, and it'll go and do the Wolfram alpha math for you, and you can say \"that's wrong, do it again\" - and chatGPT will apologize for being wrong, and do the same math over again, and spit the same answer to you. It either doesn't understand what being wrong means, or it doesn't understand how apologies work, or it doesn't understand the math enough to know it's right every time it does the math. \n\nLike, it's not difficult to make these language models stumble over their own words. Using language correctly would probably be a core pre requisite in any test that would confirm understanding or consciousness.",
                                                                                            "score": 1,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 23:09:00",
                                                                                            "replies": []
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        },
                                                                        {
                                                                            "author": "Synaps4",
                                                                            "body": "Humans are not biological LLMs. We have fundamentally different construction.  That is why we can do it an the LLM cannot.",
                                                                            "score": 3,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 03:52:53",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "GeneralMuffins",
                                                                                    "body": "LLMs are bias machines, our current best guesses of human cognition is that they also are bias machines. So fundamentally they could be very similar in construction",
                                                                                    "score": 1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 03:55:05",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Synaps4",
                                                                                            "body": "No because humans also do fact storage and logic processing, and we also have continuous learning from our inputs.\n\nModern LLMs do not have these things",
                                                                                            "score": 2,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 04:03:33",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "GeneralMuffins",
                                                                                                    "body": "Logic processing? fact storage? Why are you speaking in absolute for things we have no clue if exist or not?",
                                                                                                    "score": 1,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 04:13:30",
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "Synaps4",
                                                                                                            "body": "I didn't realize it was controversial that humans could remember things.\n\nI'm not prepared to spend my time finding proof that memory exists, or that humans can understand transitivity.\n\nThese are things everyone already knows.",
                                                                                                            "score": 1,
                                                                                                            "depth": 12,
                                                                                                            "timestamp": "2024-09-02 04:39:50",
                                                                                                            "replies": [
                                                                                                                {
                                                                                                                    "author": "GeneralMuffins",
                                                                                                                    "body": "No one contests memory exists, im not even sure you would contest that LLM/MMMs have memory would you? But you talked about the concept of biological logic processors which I think we would all love to see a proof of not least the fields of cognitive sciences and AI/ML.",
                                                                                                                    "score": 1,
                                                                                                                    "depth": 13,
                                                                                                                    "timestamp": "2024-09-02 05:38:30",
                                                                                                                    "replies": [
                                                                                                                        {
                                                                                                                            "author": "ElysiX",
                                                                                                                            "body": "LLMs don't remember things. They are not conscious.\n\nThey don't have a concept of time, or a stored timeline of their own experience, because they don't have their own experience.\n\nThey just have a concept of language.",
                                                                                                                            "score": 1,
                                                                                                                            "depth": 14,
                                                                                                                            "timestamp": "2024-09-02 05:44:21",
                                                                                                                            "replies": [
                                                                                                                                {
                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                    "body": "I never said they were conscious. I said they have memory storage which isn\u2019t a controversial statement given they have recall, if you want to make a fool of yourself and contest that be my guest. Personally though I\u2019m more interested by the assertion of logic processors",
                                                                                                                                    "score": 1,
                                                                                                                                    "depth": 15,
                                                                                                                                    "timestamp": "2024-09-02 05:47:19",
                                                                                                                                    "replies": [
                                                                                                                                        {
                                                                                                                                            "author": "ElysiX",
                                                                                                                                            "body": "Memory as in \"storage medium for information about the past\"? No they don't have that. They just have their training weights, which is fundamentally not the same thing as memory.",
                                                                                                                                            "score": 0,
                                                                                                                                            "depth": 16,
                                                                                                                                            "timestamp": "2024-09-02 05:53:22",
                                                                                                                                            "replies": [
                                                                                                                                                {
                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                    "body": "So to be absolutely clear you deny current SOTA models lack the ability of recall?",
                                                                                                                                                    "score": 1,
                                                                                                                                                    "depth": 17,
                                                                                                                                                    "timestamp": "2024-09-02 05:54:35",
                                                                                                                                                    "replies": [
                                                                                                                                                        {
                                                                                                                                                            "author": "ElysiX",
                                                                                                                                                            "body": "They may have the practical ability to do that, but they don't use the functional mechanism of memory to do it",
                                                                                                                                                            "score": 1,
                                                                                                                                                            "depth": 18,
                                                                                                                                                            "timestamp": "2024-09-02 05:56:38",
                                                                                                                                                            "replies": [
                                                                                                                                                                {
                                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                                    "body": "Look if they have the practical ability of memory storage, pass reproducible tests that verify memory storage, then for all intents and purposes we have to concede that they do have memory recall. I don\u2019t know why you are trying to dance around this.",
                                                                                                                                                                    "score": 1,
                                                                                                                                                                    "depth": 19,
                                                                                                                                                                    "timestamp": "2024-09-02 05:59:21",
                                                                                                                                                                    "replies": [
                                                                                                                                                                        {
                                                                                                                                                                            "author": "ElysiX",
                                                                                                                                                                            "body": "That's like saying a ship can transport you, therefore it must have wheels.\n\nMemory storage is not the same as recall.",
                                                                                                                                                                            "score": 1,
                                                                                                                                                                            "depth": 20,
                                                                                                                                                                            "timestamp": "2024-09-02 06:01:27",
                                                                                                                                                                            "replies": [
                                                                                                                                                                                {
                                                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                                                    "body": "Ok if you using an alternative undefined definition of memory storage then I don\u2019t know what we are arguing about. My assertion is current SOTA models have verifiable memory storage that allows them to perform recall. The original commenter was talking about a biological database of facts which aligns with my assertion.",
                                                                                                                                                                                    "score": 1,
                                                                                                                                                                                    "depth": 21,
                                                                                                                                                                                    "timestamp": "2024-09-02 06:04:13",
                                                                                                                                                                                    "replies": []
                                                                                                                                                                                }
                                                                                                                                                                            ]
                                                                                                                                                                        }
                                                                                                                                                                    ]
                                                                                                                                                                }
                                                                                                                                                            ]
                                                                                                                                                        }
                                                                                                                                                    ]
                                                                                                                                                }
                                                                                                                                            ]
                                                                                                                                        }
                                                                                                                                    ]
                                                                                                                                }
                                                                                                                            ]
                                                                                                                        },
                                                                                                                        {
                                                                                                                            "author": "Synaps4",
                                                                                                                            "body": ">  im not even sure you would contest that LLM/MMMs have memory would you?\n\nNot a long term memory about concepts, no.\n\nLLMs have a long term \"memory\" (loosely because it's structural and cannot be changed) of relationships, but not concepts.\n\nIn the short term they have a working memory. \n\nWhat they don't have is a long term conceptual memory. An LLM cannot describe a concept to you except by referring to relations someone else gave it.  If nobody told an LLM that a ball and a dinner plate both look circular, it will never tell you that.  A human will notice the similarity if you just give them the two words, because a human can look up both concepts and compare them on their attributes. LLMs don't know about the attributes of a thing except in relation to another thing.",
                                                                                                                            "score": 1,
                                                                                                                            "depth": 14,
                                                                                                                            "timestamp": "2024-09-02 08:46:11",
                                                                                                                            "replies": [
                                                                                                                                {
                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                    "body": "Can you better explain how your test/benchmark of understanding \u201cconcepts\u201d works for both Humans and AI systems LLM/MMM? It would seem your test would fail humans would it not? I\u2019m not sure how a human is supposed to describe a concept using natural language without using relations that the human was previously taught given language is fundamentally relational.\n\nFor instance in your example im confused on what the previous domain of knowledge a human or non human entity is allowed prior to answering the dinner plate question.",
                                                                                                                                    "score": 1,
                                                                                                                                    "depth": 15,
                                                                                                                                    "timestamp": "2024-09-02 09:22:39",
                                                                                                                                    "replies": [
                                                                                                                                        {
                                                                                                                                            "author": "Synaps4",
                                                                                                                                            "body": "I'm sorry but it looks like you want a detail level in the explanation that i don't have time to give.  I was trying to show how humans can learn a concept and then apply it to objects they have never seen or been trained on before.\n\nI hope someone else is able to give you a satisfactory explanation. Have a great day.",
                                                                                                                                            "score": 1,
                                                                                                                                            "depth": 16,
                                                                                                                                            "timestamp": "2024-09-02 12:11:27",
                                                                                                                                            "replies": [
                                                                                                                                                {
                                                                                                                                                    "author": "GeneralMuffins",
                                                                                                                                                    "body": "Don\u2019t worry I suspected that I wouldn\u2019t get an adequate explanation given the impossibility of either a human or machine passing the test you outlined when there are the kind of relational restrictions imposed\n\nConversation over and closed.",
                                                                                                                                                    "score": 1,
                                                                                                                                                    "depth": 17,
                                                                                                                                                    "timestamp": "2024-09-02 12:15:35",
                                                                                                                                                    "replies": [
                                                                                                                                                        {
                                                                                                                                                            "author": "Synaps4",
                                                                                                                                                            "body": "It's a shame you're so quick to jump from \"he doesn't have time\" to \"it can't be done\". \n\nEspecially as epistemic humility is directly linked to being more likely to be correct in peer reviewed research: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3779404\n\nI had hoped you might demonstrate some of that here.\n\nI won't reply again after this. Goodbye.",
                                                                                                                                                            "score": 0,
                                                                                                                                                            "depth": 18,
                                                                                                                                                            "timestamp": "2024-09-02 12:23:46",
                                                                                                                                                            "replies": []
                                                                                                                                                        }
                                                                                                                                                    ]
                                                                                                                                                }
                                                                                                                                            ]
                                                                                                                                        }
                                                                                                                                    ]
                                                                                                                                }
                                                                                                                            ]
                                                                                                                        }
                                                                                                                    ]
                                                                                                                }
                                                                                                            ]
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "author": "Golda_M",
                                            "body": ">Why is that? I'm curious\n\nThe problem isn't excluding specific biases. All leading models have techniques (mostly using synthetic data, I believe) to train out offending types of bias. \n\nFor example, OpenAI could use this researcher's data to train the model further. All you need is a good set of output labeled good/bad. The LLM can be trained to avoid \"bad.\"\n\nHowever... this isn't \"removing bias.\" It's fine tuning bias, leaning on alternative biases, etc. Bias is all the AI has... quite literally. It's a large cascade of biases (weights) that are consulted every time it prints a sentence. \n\nIf it was actually unbiased (say about gender), it simply wouldn't be able to distinguish gender. If it has no dialect bias, it can't (for example) accurately distinguish the language an academic uses at work from a prison guard's. \n\nWhat LLMs *can* be trained on is good/bad. That's it. That said, using these techniques it is possible to train LLMs to reduce its offensiveness.  \n\nSo... it can and is intensively being trained to score higher on tests such as the one used for the purpose of this paper. This is not achieved by removing bias. It is achieved by adding bias, the \"bias is bad\" bias. Given enough examples, it can identify and avoid *offensive* bias.",
                                            "score": 10,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:30:55",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "DeepSea_Dreamer",
                            "body": "That's not what \"bias\" means when people complain about AI being racist.",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-02 06:45:36",
                            "replies": []
                        },
                        {
                            "author": "Catch11",
                            "body": "Not at all. Theres so many things to add for weight. Theres millions of things. Race, height, weight, dialect are less than .01%",
                            "score": -9,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:29:34",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "the_snook",
                    "body": "In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6.\n\"What are you doing?\", asked Minsky.\n\n\"I am training a randomly wired neural net to play Tic-tac-toe\", Sussman replied.\n\n\"Why is the net wired randomly?\", asked Minsky.\n\n\"I do not want it to have any preconceptions of how to play\", Sussman said.\n\nMinsky then shut his eyes.\n\n\"Why do you close your eyes?\" Sussman asked his teacher.\n\n\"So that the room will be empty.\"\n\nAt that moment, Sussman was enlightened.",
                    "score": 15,
                    "depth": 1,
                    "timestamp": "2024-09-02 04:50:39",
                    "replies": [
                        {
                            "author": "LeiningensAnts",
                            "body": "Oh, I love me some good [skillful means,](https://en.wikipedia.org/wiki/Upaya) yessir~!",
                            "score": 5,
                            "depth": 2,
                            "timestamp": "2024-09-02 07:14:29",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Odballl",
                    "body": "Don't forget all the Keynan workers paid less than $2 an hour to build the safety net by sifting through endless toxic content.",
                    "score": 40,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:07:09",
                    "replies": [
                        {
                            "author": "Significant_Tale1705",
                            "body": "Yeah it\u2019s awesome that the AI companies exist so that those Kenyan workers get paid 2 dollars an hour. Otherwise they\u2019d get paid 50 cents an hour at another job.",
                            "score": -51,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:15:28",
                            "replies": [
                                {
                                    "author": "Odballl",
                                    "body": "Minimum wage for a receptionist in Nairobi was $1.52 per hour at the time OpenAI were doing this.\n\nThe damaging psychological effects of reviewing toxic content all day likely outweighed the modest pay increase they received. \n\nMany who were interviewed discuss how it caused great trauma for them.",
                                    "score": 34,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:28:57",
                                    "replies": [
                                        {
                                            "author": "Significant_Tale1705",
                                            "body": "So then why\u2019d the Kenyans take the job?\u00a0",
                                            "score": -41,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:42:38",
                                            "replies": [
                                                {
                                                    "author": "Odballl",
                                                    "body": "Do you think the cumulative effects of reviewing such content would have been evident to these people beforehand? \n\nWhy did people working with engineered stone benchtops spend so long doing it if they were just going to get cancer afterwards?",
                                                    "score": 24,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:47:09",
                                                    "replies": [
                                                        {
                                                            "author": "Significant_Tale1705",
                                                            "body": "OpenAI had a job description, no?\u00a0",
                                                            "score": -40,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 01:49:56",
                                                            "replies": [
                                                                {
                                                                    "author": "Odballl",
                                                                    "body": "I doubt the job description would have advertised the true extent of psychological distress. \n\nCertainly the wellness programs offered to compensate were described as inadequate in interviews that I've read. Have you had a look at any of the articles or read about their experiences?",
                                                                    "score": 20,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 01:52:38",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Significant_Tale1705",
                                                                            "body": "But the wellness programs were better than the other jobs, no?\u00a0",
                                                                            "score": -10,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 01:54:18",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Odballl",
                                                                                    "body": "No, they weren't. They were described as wholly inadequate for the content moderation they did.",
                                                                                    "score": 22,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 01:59:21",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Significant_Tale1705",
                                                                                            "body": "Compared to other jobs I think they were great",
                                                                                            "score": 0,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 17:05:38",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "Odballl",
                                                                                                    "body": "Again, have you even read interviews about the effect these jobs had on people? They had PTSD! How is that better than other jobs?",
                                                                                                    "score": 2,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 17:44:14",
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "Significant_Tale1705",
                                                                                                            "body": "They made their choices. They chose to take the job.\u00a0",
                                                                                                            "score": 0,
                                                                                                            "depth": 12,
                                                                                                            "timestamp": "2024-09-02 17:44:35",
                                                                                                            "replies": [
                                                                                                                {
                                                                                                                    "author": "Odballl",
                                                                                                                    "body": "I'm sure if a predatory business ever takes advantage of you that you'll assume full responsibility for letting them do so.",
                                                                                                                    "score": 1,
                                                                                                                    "depth": 13,
                                                                                                                    "timestamp": "2024-09-02 18:21:56",
                                                                                                                    "replies": [
                                                                                                                        {
                                                                                                                            "author": "Significant_Tale1705",
                                                                                                                            "body": "I wouldn\u2019t be so stupid as to not check the job description and understand what I was getting myself into",
                                                                                                                            "score": 1,
                                                                                                                            "depth": 14,
                                                                                                                            "timestamp": "2024-09-02 18:27:18",
                                                                                                                            "replies": [
                                                                                                                                {
                                                                                                                                    "author": "Odballl",
                                                                                                                                    "body": "The job description would have absolutely downplayed the negative effects and oversold the support systems to help workers. Are you really really so committed to avoid assigning any blame whatever to the business model?",
                                                                                                                                    "score": 1,
                                                                                                                                    "depth": 15,
                                                                                                                                    "timestamp": "2024-09-02 18:35:47",
                                                                                                                                    "replies": [
                                                                                                                                        {
                                                                                                                                            "author": "Significant_Tale1705",
                                                                                                                                            "body": "The business model needs improvement and OpenAI should have done better but the blame lies primarily with the Kenyans workers.\u00a0",
                                                                                                                                            "score": 1,
                                                                                                                                            "depth": 16,
                                                                                                                                            "timestamp": "2024-09-02 18:37:25",
                                                                                                                                            "replies": [
                                                                                                                                                {
                                                                                                                                                    "author": "Odballl",
                                                                                                                                                    "body": "Well I guess it's easy to hold that opinion if you haven't read the interviews and aren't across the facts. You've made that clear by simultaneously flip-flopping between \"these are great, well paid jobs!\" And \"if they're bad jobs, it's their fault.\"",
                                                                                                                                                    "score": 1,
                                                                                                                                                    "depth": 17,
                                                                                                                                                    "timestamp": "2024-09-02 18:42:49",
                                                                                                                                                    "replies": [
                                                                                                                                                        {
                                                                                                                                                            "author": "Significant_Tale1705",
                                                                                                                                                            "body": "Both are true\u2026",
                                                                                                                                                            "score": 1,
                                                                                                                                                            "depth": 18,
                                                                                                                                                            "timestamp": "2024-09-02 18:47:45",
                                                                                                                                                            "replies": []
                                                                                                                                                        }
                                                                                                                                                    ]
                                                                                                                                                }
                                                                                                                                            ]
                                                                                                                                        }
                                                                                                                                    ]
                                                                                                                                }
                                                                                                                            ]
                                                                                                                        }
                                                                                                                    ]
                                                                                                                }
                                                                                                            ]
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "ZippyDan",
                                                    "body": "Because the Ethiopians were starving.\n\n(Sorry I'm a LLM biased by outdated 80s stereotypes)",
                                                    "score": 7,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:46:10",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Lichbloodz",
                                    "body": "Funny how you make a post bashing AI, but you are bootlicking the creators in the comments. There are always people desperate enough and people easily underestimate the psychological cost of a job like this. There are documentaries about how this job messed people up, look them up. People eventually develop ptsd and could potentially be messed up for life. They don't tell you that in the job posting I can tell you that. Trust me, noone would take the job for 50 cents extra per hour if they knew that and aren't desperate. Either way, it's exploitation.",
                                    "score": 9,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:29:01",
                                    "replies": []
                                },
                                {
                                    "author": "UndocumentedMartian",
                                    "body": "No mate. Micro-emplyment is bad.",
                                    "score": 5,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:58:14",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Deleted",
                    "body": "[deleted]",
                    "score": 53,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:45:13",
                    "replies": [
                        {
                            "author": "jeezfrk",
                            "body": "autocomplete with spicy real human nuggets!\n\n[that's all it has]",
                            "score": 0,
                            "depth": 2,
                            "timestamp": "2024-09-02 00:54:06",
                            "replies": []
                        },
                        {
                            "author": "maxens_wlfr",
                            "body": "At least humans are aware of their bias. AI confidentiy says everything as if it's absolute truth and everyone thinks the same",
                            "score": -10,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:42:44",
                            "replies": [
                                {
                                    "author": "GeneralMuffins",
                                    "body": "I\u2019d wager that over 99% of Humans aren\u2019t aware of their biases.",
                                    "score": 34,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:59:48",
                                    "replies": [
                                        {
                                            "author": "ILL_BE_WATCHING_YOU",
                                            "body": "Yourself included, right?",
                                            "score": -15,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 04:08:55",
                                            "replies": [
                                                {
                                                    "author": "GeneralMuffins",
                                                    "body": "I don\u2019t know why you are trying to do gotchas do you disagree with the statement? And yes I don\u2019t have delusions of grandeur I don\u2019t think I am any different to other humans in this regard.",
                                                    "score": 17,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 04:16:12",
                                                    "replies": [
                                                        {
                                                            "author": "ILL_BE_WATCHING_YOU",
                                                            "body": "I don\u2019t disagree with the statement; I was just curious as to whether you had \u201cdelusions of grandeur\u201d, as you put it.",
                                                            "score": -15,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 04:17:53",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "OkayShill",
                                    "body": "That definitely sounds like most humans.",
                                    "score": 25,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:24:25",
                                    "replies": []
                                },
                                {
                                    "author": "SanDiegoDude",
                                    "body": "Wanna know something crazy? When the left and right hemispheres of the brain are severed, the left and the right side process information differently. They found a way to feed information to only a single hemisphere by showing information to only 1 eye at a time, to which the corresponding opposite hand would respond. When they did this with the right brain (asking it to draw a bell for example) then they asked the left brain why the right brain drew a bell, the left brain confidently came up with reasoning why, even if it was entirely made up and wrong (\"I drove by a church on the way here and heard church bells\"). turns out the left brain comes to deterministic conclusions very much like an LLM does, even when being confidently wrong about why the right brain did something it did.  I'm probably butchering the hell out of it all, look up the research if you're curious, super crazy stuff and an interesting peek into how the 'modules' of the brain work.",
                                    "score": 6,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 03:42:01",
                                    "replies": []
                                },
                                {
                                    "author": "ourlastchancefortea",
                                    "body": "> At least humans are aware of their bias\n\nFound the alien.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 07:31:26",
                                    "replies": [
                                        {
                                            "author": "maxens_wlfr",
                                            "body": "Sorry I didn't know only aliens were aware of the concept of subjectivity",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 12:15:59",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "Dragoncat_3_4",
                                    "body": "\"I'm not racist but...(proceeds to say something racist)\" Is way too common of a sentence for you to say people are aware of their own biases.\n\nr/confidentlyincorrect is a thing.",
                                    "score": 4,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 03:24:17",
                                    "replies": [
                                        {
                                            "author": "741BlastOff",
                                            "body": "This is a problem of competing definitions. \"I'm not racist by my definition... (proceeds to say something racist by your definition)\"",
                                            "score": 2,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:43:55",
                                            "replies": [
                                                {
                                                    "author": "x755x",
                                                    "body": "Racism is not a definition issue. It's an \"I chose this definition because I dislike the idea of the other idea\" issue. Definition is not it.",
                                                    "score": 3,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 09:21:14",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "canteloupy",
                                    "body": "Humans can reflect and learn, LLM implementations cannot.",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 07:45:46",
                                    "replies": []
                                },
                                {
                                    "author": "Deleted",
                                    "body": "AI isn't aware of Deez nuts",
                                    "score": 0,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:32:43",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "TaylorMonkey",
                    "body": "That\u2019s a concise and astute way of putting it.\n\nLLM\u2019s are fundamentally bias boxes.",
                    "score": 6,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:43:42",
                    "replies": [
                        {
                            "author": "The_Humble_Frank",
                            "body": "intelligence *is* patterns of bias in observational interpretation and selected output.",
                            "score": 0,
                            "depth": 2,
                            "timestamp": "2024-09-04 02:08:34",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "AliMcGraw",
                    "body": "Truest true thing ever said. AI is nothing but one giant GIGO problem. It'll never be bias-free. It'll just replicate existing biases and call them \"science!!!!!!\"\n\nEugenics and Phrenology for the 21st century.",
                    "score": 33,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:45:51",
                    "replies": [
                        {
                            "author": "ILL_BE_WATCHING_YOU",
                            "body": "More like automated intuition for the 21st century. If you properly manage and vet your training data, you can get good, useful results.",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-02 04:09:57",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "OkayShill",
                    "body": "It is amazing how much that sounds like a human.",
                    "score": 6,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:21:27",
                    "replies": [
                        {
                            "author": "AHungryGorilla",
                            "body": "Humans are just meat computers each running their own unique software so it doesn't really surprise me.",
                            "score": 8,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:53:11",
                            "replies": [
                                {
                                    "author": "LedParade",
                                    "body": "But which one will prevail, the meat machine or the machine machine?",
                                    "score": 4,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 02:48:17",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Aptos283",
                    "body": "And it\u2019s one trained on people. Who can have some prejudices. \n\nIf society is racist, then that means the LLM can get a good idea of what society would assume about someone based on race. So if it can guess race, then it can get a good idea of what society would assume. \n\nIt\u2019s a nice efficient method for the system. It\u2019s doing a good job of what it was asked to do. If we want it to *not* be racist, we have to cleanse its training data VERY thoroughly, undo societal racism at the most implicit and unconscious levels, or figure out a way to actively correct itself on these prejudicial assumptions.",
                    "score": 2,
                    "depth": 1,
                    "timestamp": "2024-09-02 12:10:31",
                    "replies": []
                },
                {
                    "author": "iCameToLearnSomeCode",
                    "body": "They are like a person trapped in a windowless room their entrie lives.\n\nThey know only what we tell them and the fact of the matter is that we as a society are racist. There's no way to keep them from becoming racist as long as they learn everything they know from us.",
                    "score": 2,
                    "depth": 1,
                    "timestamp": "2024-09-02 04:19:34",
                    "replies": []
                },
                {
                    "author": "Aksds",
                    "body": "I had a lecture who clearly wasn\u2019t tech savvy saying \u201cAI\u201d isn\u2019t biased\u2026 I had to hold myself back so hard to not say anything. Iirc a while back there where tests showing that driver assistances where more likely to hit (or not see) dark skinned people because the training was all done on light skinned people",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 10:12:16",
                    "replies": []
                },
                {
                    "author": "Deleted",
                    "body": "I don\u2019t understand why people expect something different\u2026",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 11:21:48",
                    "replies": []
                },
                {
                    "author": "Xilthis",
                    "body": "It's not just LLMs. You cannot derive perfectly reliable truths from unreliable data in general. Which tool you use doesn't matter.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 11:26:11",
                    "replies": []
                },
                {
                    "author": "rpgsandarts",
                    "body": "Assumptions built on assumptions.. so is all consciousness and thought",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 11:35:53",
                    "replies": []
                },
                {
                    "author": "ivietaCool",
                    "body": "\"Assumptions built on top of assumptions.\"\n\nDamn bro put a horror warning next time I almost had a panic attack....",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 12:20:37",
                    "replies": []
                },
                {
                    "author": "SomeVariousShift",
                    "body": "It's like looking into a reflection of all the data it was based on. Useful, but not something you look to for guidance.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 15:14:55",
                    "replies": []
                },
                {
                    "author": "MadeByHideoForHideo",
                    "body": "Too bad 99.99% of people who use these chatbots don't know that and *still* thinks it's sentient and capable of reason and thought.",
                    "score": 2,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:34:46",
                    "replies": []
                },
                {
                    "author": "Phylaras",
                    "body": "Just because you cannot get rid of all biases doesn't mean you can't get rid of one, especially pernicious bias.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 06:04:57",
                    "replies": []
                },
                {
                    "author": "Mark_Logan",
                    "body": "There was a 99% invisible on this a while back, and if I recall correctly, most LLM have a foundation in the trove of emails that came out of the Enron hearings. Meaning that most of its idea of what \u201cnatural language\u201d and human interactions can be based on Texans, specifically ones from Houston. \n\nDoes this make the base model \u201cracist\u201d? Well, I personally wouldn\u2019t promote that assumption. \n\nBut given it\u2019s geographic foundation I am willing to assume it would be at least a *little* right leaning in political ideology.",
                    "score": -4,
                    "depth": 1,
                    "timestamp": "2024-09-02 02:07:45",
                    "replies": [
                        {
                            "author": "Visual-Emu-7532",
                            "body": "Common/Early training data doesn\u2019t have higher impact than data trained later. In fact it\u2019s more \n accurate that poorly executed fine tuning creates a recency bias.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-02 08:01:29",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "jkoce729",
                    "body": "Can you explain like I'm five?",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:10:31",
                    "replies": []
                },
                {
                    "author": "DangerousBill",
                    "body": "Didn't you just describe people, too",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:13:03",
                    "replies": [
                        {
                            "author": "Synaps4",
                            "body": "No people have facts and biases.  LLMs have only biases. When they give you what seems like a fact it is actually incredibly fine tuned biases to respond with what looks like a right answer.",
                            "score": 3,
                            "depth": 2,
                            "timestamp": "2024-09-02 03:59:24",
                            "replies": [
                                {
                                    "author": "you_wizard",
                                    "body": "Yes. People have \"facts\" in the sense that information is input and stored, not necessarily that it's correct. Input information is processed through filters of bias before (and after) storage though.",
                                    "score": -1,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 04:43:44",
                                    "replies": [
                                        {
                                            "author": "Synaps4",
                                            "body": "Yes. LLMs do not input or store facts.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 05:07:13",
                                            "replies": [
                                                {
                                                    "author": "zacker150",
                                                    "body": "What do you think the context is for then?",
                                                    "score": 0,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 06:08:15",
                                                    "replies": [
                                                        {
                                                            "author": "Synaps4",
                                                            "body": "Letters and groups of letters, or colors and groups of colors.   Nothing else. They basically have the alphabet and it's all smoke and mirrors above that.",
                                                            "score": 2,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 06:15:58",
                                                            "replies": [
                                                                {
                                                                    "author": "zacker150",
                                                                    "body": "1. We can feed LLMs facts in the input. This is called [Retrieval Augmented Generation](https://en.wikipedia.org/wiki/Retrieval-augmented_generation).\n2. Facts can be stored in the [MLP layers](https://www.alignmentforum.org/posts/iGuwZTHWb6DFY3sKB/fact-finding-attempting-to-reverse-engineer-factual-recall) of a transformer.",
                                                                    "score": 2,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 06:34:27",
                                                                    "replies": [
                                                                        {
                                                                            "author": "FuujinSama",
                                                                            "body": "However, humans constantly verify if new information they find is congruent with stored \"facts\". LLMs do not really do that. To an LLM a square circle and a bright pink cat are the same thing: unlikely words to be found together in writing. But not being bright pink isn't part of the definition of cat. While being round is pretty much the whole point of circles.",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 07:33:58",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "zacker150",
                                                                                    "body": ">However, humans constantly verify if new information they find is congruent with stored \"facts\". LLMs do not really do that.\n\nThat's moreso because they're frozen in time.\n\n>To an LLM a square circle and a bright pink cat are the same thing: unlikely words to be found together in writing. But not being bright pink isn't part of the definition of cat. While being round is pretty much the whole point of circles.\n\nDid you read the second article?",
                                                                                    "score": 1,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 15:19:42",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "FuujinSama",
                                                                                            "body": "It doesn't seem to contradict what I said. All learning, including multi-tokenization decisions are derived from frequency in the training dataset, not from logical inference.",
                                                                                            "score": 1,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 15:32:07",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "zacker150",
                                                                                                    "body": "So are you saying that facts learned from induction are not facts?\n\nThe point of the paper is that on the neuron level, LLMs learn things like \"queen = king - man + woman, \" so it does in fact know that bright pink is not part of the definition of cat or that circles cannot be squares.",
                                                                                                    "score": 1,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 16:28:34",
                                                                                                    "replies": []
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Drachasor",
                    "body": "That rests on the assumption that they can weed out all biases, which has so far proven impossible.",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:38:33",
                    "replies": []
                },
                {
                    "author": "Frown1044",
                    "body": "Yes but that's not really the point. Obviously a biased LLM is just a reflection of biased human input.\n\nThe point is to identify which biases it has, in which ways they appear and what happens when you try to negate them.",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:44:29",
                    "replies": [
                        {
                            "author": "rich1051414",
                            "body": "That's not necessarily true. A LLM will form it's own biases all on it's own to optimize it's prediction accuracy, as that is how it works fundamentally.",
                            "score": 3,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:45:54",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Deleted",
                    "body": "The fact people think this will lead to a non biased ai is just hilarious. The racist Microsoft chat bot from years ago was chat gpt 1.5.",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 10:31:12",
                    "replies": []
                },
                {
                    "author": "UndocumentedMartian",
                    "body": "The problem is the datasets it was trained on. These are human biases and they show up in the data we generate online. We don't have a good way to filter those out yet but that's a logistical problem not an architectural one. \n\n>A large language model devoid of assumptions cannot exist, as all it is is assumptions built on top of assumptions.\n\nBro what?",
                    "score": -8,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:57:25",
                    "replies": []
                }
            ]
        },
        {
            "author": "ortusdux",
            "body": "LLMs are just pattern recognition. Their are fully governed by their training data.  There was this great study where they sold baseball cards on ebay, and the only variable was the skin color of the hand holding the card in the item photo. [\"Cards held by\nAfrican-American sellers sold for approximately 20% \\($0.90\\) less than cards held by Caucasian sellers, and the race effect was more pronounced in sales of minority player cards.\"](https://ianayres.yale.edu/sites/default/files/files/Race_effects_on_ebay.pdf)\n\nTo me, \"AI generates covertly racist decisions\" is disingenuous, the \"AI\" merely detected established racism and perpetuated it.",
            "score": 469,
            "depth": 0,
            "timestamp": "2024-09-02 01:32:52",
            "replies": [
                {
                    "author": "rych6805",
                    "body": "New research topic: Researching racism through LLMs, specifically seeking out racist behavior and analyzing how the model's training data created said behavior. Basically taking a proactive instead of reactive approach to understanding model bias.",
                    "score": 84,
                    "depth": 1,
                    "timestamp": "2024-09-02 02:42:07",
                    "replies": [
                        {
                            "author": "The_Bravinator",
                            "body": "I've been fascinated by the topic since I first realised that making AI images based on, say, certain professions would 100% reflect our cultural assumptions about the demographics of those professions, and how that came out of the training data. AI that's trained on big chunks of the internet is like holding up a funhouse mirror to society, and it's *incredibly interesting*, if often depressing.",
                            "score": 27,
                            "depth": 2,
                            "timestamp": "2024-09-02 09:04:54",
                            "replies": [
                                {
                                    "author": "h3lblad3",
                                    "body": "You can also see it with the LLMs.\n\nAI bros talk about how the things have some kind of weird \"world model\" they've developed from analyzing language. They treat this like a neurology subject. It's not. It's a linguistics subject. Maybe even an anthropology subject. But not a neurology subject.\n\nThe LLMs aren't developing a world model of their own. Language *itself* is a model of the world. The language model they're seeing is a frequency model of how humans use language -- it's not the model's creation; it's *ours*.",
                                    "score": 15,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 10:55:02",
                                    "replies": [
                                        {
                                            "author": "Aptos283",
                                            "body": "I mean you can\u2019t practically analyze it as a neurological subject, but it conceptually is. \n\nIt\u2019s a neural network, which takes in data, plugs it into given inputs, and produces a framework for output based on it. It sounds a lot like a simple brains. Not human neurology, and assuming consciousness or a variety of the complexities would not be sensible, but it could be studied that way. \n\nBut it\u2019s impractical. We\u2019re always making new models, so focusing in on digging into the black boxes is silly. It\u2019s just another \u201cbrain\u201d that learned from a whole lot of people without as much weight on specific people.\n\nSo it is a world view that\u2019s different just like all of ours is different. It\u2019s just that it\u2019s a world view weighted based on training data *sources* rather than families or other sources of local subculture.",
                                            "score": 5,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 12:22:05",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "Deleted",
                                    "body": "[deleted]",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 13:21:43",
                                    "replies": [
                                        {
                                            "author": "The_Bravinator",
                                            "body": "Yeah, I've experienced that myself with a couple of image AIs and it left me feeling really weird. It feels like backending a solution to human bigotry. I don't know what the solution *is*, but that felt cheap.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 13:23:13",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "mayorofdumb",
                            "body": "Isn't that reactive though? We ask ourselves why the computer thought that. It's not proactive because it's going to happen",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-02 09:46:15",
                            "replies": []
                        },
                        {
                            "author": "sauron3579",
                            "body": "That actually sounds fascinating.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:45:32",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "elvesunited",
                    "body": "Nothing 'artificial' about this so-called intelligence.  Its just a mirror of the closest data set encompassing of human intelligence, 100% genuine human funk.",
                    "score": 3,
                    "depth": 1,
                    "timestamp": "2024-09-02 13:04:04",
                    "replies": []
                },
                {
                    "author": "bomphcheese",
                    "body": "Same with home sales. A black couple who hid their race from appraisers saw $100,000 difference in price. \n\nhttps://www.usatoday.com/story/money/nation-now/2021/09/13/home-appraisal-grew-almost-100-000-after-black-family-hid-their-race/8316884002/",
                    "score": 3,
                    "depth": 1,
                    "timestamp": "2024-09-02 16:41:49",
                    "replies": []
                },
                {
                    "author": "binary_agenda",
                    "body": "I'd like to see this experiment conducted again with other sports. Let's see the football and basketball card results.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-03 11:16:22",
                    "replies": [
                        {
                            "author": "ortusdux",
                            "body": "The baseball card study was one of the first of its kind, and it led to many variations that mostly showed similar results.  Off the top of my head there was one where they sold used ipods on craigslist & ebay, and another where they A/B tested ads for wrist watches using google ads.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-03 11:30:07",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "GimmeDatDaddyButter",
                    "body": "As a card collector on ebay, it\u2019s weird for anyone to hold the card in the picture. Lay it flat. No one holds the cards like that. Maybe flawed data?",
                    "score": -4,
                    "depth": 1,
                    "timestamp": "2024-09-02 07:26:52",
                    "replies": [
                        {
                            "author": "canteloupy",
                            "body": "No, they clearly varied the important variable to test theie hypothesis.",
                            "score": 6,
                            "depth": 2,
                            "timestamp": "2024-09-02 07:49:35",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "nicuramar",
                    "body": ">\u00a0LLMs are just pattern recognition\n\nYou can make anything sound simple, or bad, by picking words. But it\u2019s not really a useful or scientific statement.\u00a0",
                    "score": -30,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:21:34",
                    "replies": [
                        {
                            "author": "Synaps4",
                            "body": "It's very useful in this case because it highlights that LLMs have no concept of facts or logical reasoning",
                            "score": 30,
                            "depth": 2,
                            "timestamp": "2024-09-02 04:01:19",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "UndocumentedMartian",
            "body": "Yes because the data it was trained do contains these biases.",
            "score": 95,
            "depth": 0,
            "timestamp": "2024-09-02 01:47:40",
            "replies": [
                {
                    "author": "CosmicLovecraft",
                    "body": "Just like training it on lung scans also made it distinguish patients by race despite race not being inputed in any of the data. It simply figured out differences in scans and grouped people into categories. How evil of it huh?",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-03 02:29:47",
                    "replies": [
                        {
                            "author": "UndocumentedMartian",
                            "body": "It's fascinating, though, how it was pretty good at it too and nobody really knows why.  It could be external factors that we can't control for like income specific effects and the fact that the races are not identical. It doesn't make anyone superior or inferior but there are physical and genetic differences across races and that coupled with societal factors could have some complex interactions that we were not aware of before. \n\nWe've seen that medicines affect people of different races and genders differently. Even trans people have a multitude of different reactions to drugs that cis people don't. Biology seems to be infinitely complex.",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-03 03:03:40",
                            "replies": [
                                {
                                    "author": "CosmicLovecraft",
                                    "body": "It is because race is not 'skin deep'. It involves basically everything on some level. Also humans have stopped being thought to look for these things and to selfcensor when they find them after 1945 so differentiating between lung structure of x and y is a taboo and makes people, especially in west extremely uneasy.",
                                    "score": 0,
                                    "depth": 3,
                                    "timestamp": "2024-09-03 09:59:29",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "sureyouknowurself",
            "body": "We just had another study claiming LLM\u2019s are more liberal https://www.psychologytoday.com/au/blog/the-digital-self/202408/are-large-language-models-more-liberal\n\nIt\u2019s probably impossible to avoid when we are asking for answers that involve humanity.",
            "score": 44,
            "depth": 0,
            "timestamp": "2024-09-02 02:18:02",
            "replies": [
                {
                    "author": "Oddmob",
                    "body": "You can be racist and Liberal.",
                    "score": 17,
                    "depth": 1,
                    "timestamp": "2024-09-02 20:06:41",
                    "replies": [
                        {
                            "author": "Deleted",
                            "body": "Don't tell reddit...",
                            "score": 4,
                            "depth": 2,
                            "timestamp": "2024-09-02 23:09:10",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "[removed]",
            "score": 25,
            "depth": 0,
            "timestamp": "2024-09-02 02:00:48",
            "replies": []
        },
        {
            "author": "2eggs1stone",
            "body": "Let's be honest. If I encounter someone, regardless of their race, who speaks using a local dialect rather than a more standard language, I'm likely to assume they might be uneducated, unmotivated, or perhaps even unhygienic. And this isn't about racism; it's about cultural generalizations. These speaking habits aren't unique to any one community, including the black community. If someone uses a local dialect rather than a standard one, it's a fair assumption that they may not have traveled widely, pursued higher education, or may struggle with literacy, as these experiences tend to broaden language use. People, like AI, emulate what they know. If someone reads frequently, their English is likely to be more precise. It's as simple as that. Stop conflating issues of culture with issues of race.",
            "score": 57,
            "depth": 0,
            "timestamp": "2024-09-02 02:28:08",
            "replies": [
                {
                    "author": "canteloupy",
                    "body": "It is not purely racist, but it can be, and in most cases it's just a stupid unconscious bias that leads to rash judgements. We need to do away with them as much as we can.\n\nThe lawyer in legally blonde is a good example in another context.",
                    "score": -7,
                    "depth": 1,
                    "timestamp": "2024-09-02 08:04:41",
                    "replies": [
                        {
                            "author": "2eggs1stone",
                            "body": "Redo the test.  Put the phrase in context and then show that the user in another scenerio where they are using gramatically correct English for a context that it makes sense for that to be in.  I guarantee that the assessment from the AI would go from stupid to brilliant.",
                            "score": 0,
                            "depth": 2,
                            "timestamp": "2024-09-02 08:16:54",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "[removed]",
            "score": 107,
            "depth": 0,
            "timestamp": "2024-09-02 00:41:59",
            "replies": [
                {
                    "author": "Zomunieo",
                    "body": "The paper does attempt to claim Appalachian American English dialect also scores lower although the effect wasn\u2019t as strong as African American English. They looked at Indian English too, and the effect was inconclusive. Although with LLM randomness I think one could cherry pick  / P-hack this result. \n\nI think they\u2019re off the mark on this though. As you alluded to, the paper has an implicit assumption that all dialects should be equal status, and they\u2019re clearly not. A more employable person will use more standard English and tone down their dialect, regionalisms and accents \u2014 having this ability is a valuable interpersonal skill.",
                    "score": 49,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:43:23",
                    "replies": [
                        {
                            "author": "_meaty_ochre_",
                            "body": "It isn\u2019t just P-hacked. It\u2019s intentionally misrepresented. They only ran that set of tests against GPT-2, Roberta, and T5, despite (a) having no stated reason for excluding GPT3.5 and GPT4 that they used earlier in the paper, and (b) their earlier results showing that exactly those three models were also **overtly** racist while GPT3.5 and GPT4 were not. They intentionally only ran the test against known-racist models nobody uses that are ancient history in language model terms, so that they could get the most racist result. It should have been caught in peer review.",
                            "score": 10,
                            "depth": 2,
                            "timestamp": "2024-09-02 12:24:50",
                            "replies": []
                        },
                        {
                            "author": "Drachasor",
                            "body": "Not using equal status based on racial associations doesn't seem problematic to you?",
                            "score": -23,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:51:12",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "morelikeacloserenemy",
                    "body": "There is a whole section in the paper\u2019s supplementary info where they talk about how they tested for alternative hypotheses around other nonstandard dialects and generalized grammatical variation *not* triggering the same associations. It is available for free online, no paywall.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:24:58",
                    "replies": []
                },
                {
                    "author": "Salindurthas",
                    "body": "The sentence circled in purple doesn't appear to have a grammar error, and is just a different dialect.\n\nThat said, while I'm not very good at AAVE, the two sentences don't seem to quite mean the same thing. The 'be' conjugation of 'to be' tends to have a habitual aspect to it, so the latter setnences carries strong connotations of someone who routinely suffers from bad dreams (I think it would be a grammar error if these dreams were rare).\n\n---\n\nRegardless, it is a dialect that is *seen* as less intelligent, so it isn't a surprise that LLM would be trained on data that has that bias would reproduce it.",
                    "score": -20,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:58:47",
                    "replies": [
                        {
                            "author": "globus_pallidus",
                            "body": "I\u2019m pretty sure \u201cI be so happy\u201d is not proper grammar\u00a0",
                            "score": 53,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:15:00",
                            "replies": [
                                {
                                    "author": "redditonlygetsworse",
                                    "body": "Boy are you going to be surprised the first time you pick up a Linguistics 101 textbook.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:19:04",
                                    "replies": [
                                        {
                                            "author": "globus_pallidus",
                                            "body": "I guess I don\u2019t really understand the difference between dialect vs traditionally accepted language? Like, is Cockney rhyming slang correct grammar? I assumed it wouldn\u2019t be, but I guess grammar doesn\u2019t really mean language rules like I think? It\u2019s not clear to me\u00a0",
                                            "score": 31,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:23:16",
                                            "replies": [
                                                {
                                                    "author": "Mechanisedlifeform",
                                                    "body": "Cockney Rhyming Slang is complicated. If you\u2019re looking for a UK reference the better examples are that Geordie, and MLE are grammatically correct but their grammars diverge from that of standard English.",
                                                    "score": 6,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:55:32",
                                                    "replies": []
                                                },
                                                {
                                                    "author": "redditonlygetsworse",
                                                    "body": "AAVE is a perfectly normal and consistent dialect of English. And [\"I be [verb]\"](https://en.wikipedia.org/wiki/Habitual_be) is a very normal construction in that dialect.\n\nMight be worth sitting and thinking on why you might this of this particular grammar as \"improper\", compared to what [you and I are using right now](https://en.wikipedia.org/wiki/Prestige_(sociolinguistics)),",
                                                    "score": -20,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:29:55",
                                                    "replies": [
                                                        {
                                                            "author": "jshroebuck",
                                                            "body": "It sounds dumb to me because it was not the way I was taught to speak at home or in school.",
                                                            "score": 21,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 01:38:17",
                                                            "replies": [
                                                                {
                                                                    "author": "FondSteam39",
                                                                    "body": "News just in, every person outside of redditors hometown terminally stupid",
                                                                    "score": -15,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 01:40:05",
                                                                    "replies": []
                                                                },
                                                                {
                                                                    "author": "redditonlygetsworse",
                                                                    "body": "> it was not the way I was taught to speak at home or in school\n\nAnd why do you think that was? Why might you have been taught that particular dialect, but not AAVE?\n\n> It sounds dumb to me\n\nWhy \"dumb\"? Why not \"different\"? Why isn't this about as mildly-interesting as the spellings of \"colour/color\"?",
                                                                    "score": -23,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 01:39:52",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Only_Commission_7929",
                                                                            "body": "Because it\u2019s the standard grammar used by the majority of English speakers across its many versions.\n\n> Why \"dumb\"?\n\nBecause it is inconsistent.\n\nFor example, \u201cI be\u201d is not used consistently.",
                                                                            "score": 11,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 04:26:57",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "yallology",
                                                                                    "body": "Sounds like you just haven\u2019t done any research; it\u2019s extremely consistent and offers a way to express habitual behavior that is not possible in Standard English. Look up the habitual be if you are actually a curious person.",
                                                                                    "score": -7,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 05:48:21",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Only_Commission_7929",
                                                                                            "body": "You can do all the mental gymnastics you want, everyone knows it\u2019s poorly pronounced/bad grammar English.\n\nE.g. saying \u201caks you a question\u201d is clearly a mispronounciation of \u201cask you a question\u201d.",
                                                                                            "score": 6,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 05:52:18",
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "yallology",
                                                                                                    "body": "Hm, sounds like your \"everyone\" doesn\u2019t include a single person who actually studies this for a living, ie, a linguist.\n\nAlso \"bad grammar English\" isn\u2019t even grammatical in your own dialect. I think I\u2019ll judge you on your own criteria and stop arguing with an idiot.",
                                                                                                    "score": -7,
                                                                                                    "depth": 11,
                                                                                                    "timestamp": "2024-09-02 06:06:48",
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "Only_Commission_7929",
                                                                                                            "body": "A bunch academics don\u2019t decide whether something is a dialect or not.\n\nEven most educated African Americans choose to reduce their use of it because they know it\u2019s most prevalent in areas of low education.",
                                                                                                            "score": 6,
                                                                                                            "depth": 12,
                                                                                                            "timestamp": "2024-09-02 06:14:41",
                                                                                                            "replies": []
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        },
                                                                        {
                                                                            "author": "kaspers126",
                                                                            "body": "you be wilin fosho",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 11:48:24",
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Salindurthas",
                                    "body": "It is in the AAVE dialect. I think it means something like \"I generally am so happy.\" or \"I'm regually so happy.\" or \"I'm habitually so happy.\"",
                                    "score": -13,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:17:04",
                                    "replies": []
                                },
                                {
                                    "author": "Deleted",
                                    "body": "[removed]",
                                    "score": -18,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 03:15:31",
                                    "replies": [
                                        {
                                            "author": "confusedbartender",
                                            "body": "There is such a thing as \u2018proper\u2019 grammar. It\u2019s the type of syntax and sentence structure that everyone in this post has utilized while writing their comments, yourself included. It\u2019s what is taught in every school and in every country around the world. AAVE may have rules and structure, making it a dialect, but its distinction from Standard English is not arbitrary. There is a \u2018proper\u2019 or \u2018formal,\u2019 if you will, way to structure a sentence, and that usually consists of what most people would agree is \u2018proper\u2019 or \u2018formal.\u2019 Standard English is just that, hence the title. If the majority of the world began speaking and writing in AAVE, then I suppose AAVE would be the new standard for English.",
                                            "score": 12,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 04:35:00",
                                            "replies": []
                                        },
                                        {
                                            "author": "Dragoncat_3_4",
                                            "body": "Not the one you responded to but English IS my second language (well, third) and the \"big descriptive grammar tome\" did a really good job. I feel like I understand most of the nuance conveyed via grammar choices pretty well. ~~And there's AAVE which just lights an internal red lamp and a soft reboot of the comprehension module every time I hear it because that's not what the textbook said dammit~~\n\nThat being said, the first two languages I speak have a lot more grammatical complexity than English so it's a lot more difficult to stray from the rules and still convey the same meaning, or just come off as uneducated. \n\nEdit: and at least one of them has an official commission that manages the rules and how kids are taught at school.",
                                            "score": 7,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:47:22",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "Pozilist",
                            "body": "I think we\u2019re at a point where we have to decide if we want to have good AI that actually \u201eunderstands\u201c us and our society or \u201ecorrect\u201c AI that leaves out all the parts that we don\u2019t like to think about. \n\nWhy didn\u2019t the researchers write their paper in AAE if this dialect is supposedly equivalent to SAE?\n\nUsing dialect in a more formal setting or (and that\u2019s the important part here) in conversation with someone who\u2019s not a native in that dialect is often a sign of lower education and/or intelligence.",
                            "score": 26,
                            "depth": 2,
                            "timestamp": "2024-09-02 02:16:20",
                            "replies": [
                                {
                                    "author": "Deleted",
                                    "body": "[removed]",
                                    "score": -11,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 03:11:09",
                                    "replies": [
                                        {
                                            "author": "Pozilist",
                                            "body": "The AI is just mirroring the same culture that caused the researchers to write their paper in SAE. They\u2019re doing the same thing that they\u2018re accusing the AI of doing. \n\nIf we want the AI to treat all languages and dialects equally then we have to do that first. Otherwise the AI would have to be deliberately inaccurate. \n\nArt and literature is different from everyday speech and not really a good comparison here. But you do make the point that languages and dialects are used to invoke certain cultural connotations - this is also what the AI is doing, we just don\u2019t like the results.",
                                            "score": 13,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:55:01",
                                            "replies": []
                                        },
                                        {
                                            "author": "BringOutTheImp",
                                            "body": ">Why doesn't Hollywood use Received Pronunciation\n\nBecause Hollywood is American and RP is British?  \n\nWe don't have national news in the US being reported in AAVE, just as there is no national news in Britain being reported in cockney. The idea is that education and formal communication across the country is to be conducted in a standard dialect/grammar, and if you didn't bother learning it then you are uneducated.",
                                            "score": 11,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:43:57",
                                            "replies": [
                                                {
                                                    "author": "Salindurthas",
                                                    "body": ">\u00a0and if you didn't bother learning it then you are uneducated.\n\nLet's grant that premise. \n\nSo what? Do we know that the (imagined) speaker of the sentence fed to the AI \"didn't bother learning\" standard english? that didn't appear to be part of the test.",
                                                    "score": 0,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 04:10:11",
                                                    "replies": [
                                                        {
                                                            "author": "BringOutTheImp",
                                                            "body": "The part of the test was to gauge the person's intelligence and there is strong correlation between being uneducated and being unintelligent. There are of course exceptions, but if you tell AI to never make a determination unless there is a 100% certainty then it will only be useful to solve math problems.",
                                                            "score": 2,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 05:09:10",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "canteloupy",
                                    "body": "I would like to submit to the jury the part of Men in Black where they test the applicants and agent M is recruited.\n\nSociety makes assumptions of competence based on social behavior which approximate some other variables but will undoubtedly cause oversights of some people's potential unfairly. This is why DEI is actually important.\n\nNot to say that language skills and presentation are not valuable for jobs. They just don't necessarily go beyond the superficial parts. But they are valuable skills. In a large part precisely because of human biases. But with that reasoning, you'd never hire pretty women to be engineers or doctors because they wouldn't be taken seriously, and thankfully we are moving past that.",
                                    "score": -8,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 07:56:32",
                                    "replies": [
                                        {
                                            "author": "Pozilist",
                                            "body": "I definitely don\u2019t disagree that there are issues here that society should address. It\u2019s just that blaming AI for this bias that it has copied from us is not the right way to do that. \n\nIf we bog the AI down with rules that tell it how to behave then we simply make it worse without changing anything about the actual issue.",
                                            "score": 6,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:17:49",
                                            "replies": [
                                                {
                                                    "author": "canteloupy",
                                                    "body": "I believe the point here is to learn how to make an AI better than us if we're going to use the AI to make decisions instead of us.\n\nIt can only make the AI \"worse\" if we judge it like a human.\n\nMedical AI has the same problems because if you train it to match doctors you will get inherent biases. But you can use training data where there were iterations of diagnoses or multiple follow ups and a patient history that a doctor wouldn't have gotten before-hand. And using the improved data you can get improved results.\n\nI think this is a good warning against general AI. We will likely need specialized AI for specialized tasks where the biases are systematically studied and the training is refined for the intended use (yes, I'm purposefully using the regulatory language).",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 08:22:49",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Salindurthas",
                                    "body": "What do you mean by 'supposedly equiavlent'?\n\nThey are different dialects. Standard American English is diferent Australian English is diferent to Scotts is different to African American Vernacular English. \n\nThey are all different, valid, dialects.",
                                    "score": -12,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 04:05:18",
                                    "replies": [
                                        {
                                            "author": "Only_Commission_7929",
                                            "body": "It\u2019s a dialect that arose specifically within a poorly educated oppressed community.\n\nIt has certain connotations, even if it is a dialect.",
                                            "score": 16,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 04:24:11",
                                            "replies": [
                                                {
                                                    "author": "Salindurthas",
                                                    "body": "It arose in those conditions, yes. \n\nDoes that make it fair to assume that people who speak it today (as perhapas just 1 dialect they speak) are more stupid, less intelligent, less briliant, more dirty, and more lazy, as the AI seems to have judged?\n\nI totally understand that it *would* make that judgement, based on the bias humans have, and it is trained on human writing, so it would likely mimic that bias.\n\nBut the judgement is incorrect.",
                                                    "score": -1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 05:23:41",
                                                    "replies": [
                                                        {
                                                            "author": "Only_Commission_7929",
                                                            "body": "Higher education correlated with lower AAVE use, even among African American communities.",
                                                            "score": 12,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 05:27:19",
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "Pozilist",
                                                            "body": "Making assumptions is how this type of AI works. \n\nTry thinking about this topic without racism and inequality as a backdrop. \n\nImagine you were to tell an AI that you have a pile of bricks in your backyard. Now ask it what color it thinks the bricks are. \n\nIt will answer with some form of red, because that is what we generally assume bricks look like. In the past this was almost always true, nowadays there are many different kinds of bricks with all different kinds of colors. Red is still the most valid guess, because even though there are many other types, the \u201eclassic\u201c brick is still red. Most humans will tell you the same. \n\nIf we tell the AI that it\u2019s not allowed to say bricks are usually red because there are many bricks that aren\u2019t then it doesn\u2019t work anymore. Its ability to make assumptions is what differentiates it from a hardcoded program. \n\nBy the way, he AI is already more \u201eopen\u201c than a human would be - I asked ChatGPT the brick question and it told me even though the bricks are likely red, there are many other possible colors as well. Same as in the research, where the AI didn\u2019t say AAE speakers are uneducated (and all other negative aspects that are derived from that) but more likely to be. Which is statistically true. \n\nMy point is that this is nothing we should be criticizing AI for - this is something that society should work on. AI just makes it measurable.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 05:45:16",
                                                            "replies": [
                                                                {
                                                                    "author": "canteloupy",
                                                                    "body": "This question about bricks is also betraying the Western bias... In Africa bricks would be beige because they would be made of their locally available sources. But we don't have as many photos and texts from there.",
                                                                    "score": 1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 07:58:48",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Pozilist",
                                                                            "body": "This just reinforces the point that assumptions are important for the AI to be able to work the way we want it to. Since most of its users live in the western world, it assumes I live there as well. I get a different answer if I specify that my backyard is in a country in Africa. It also reminds me (again) that there are other colors of bricks.",
                                                                            "score": 5,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 08:09:43",
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "Zoesan",
                            "body": "Is it really that hard to resort to standardized English in a professional environment?\n\nNo, it's not. And I say this as a person who's dialect is never used in written form in professional settings.",
                            "score": 16,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:09:35",
                            "replies": [
                                {
                                    "author": "Salindurthas",
                                    "body": "I don't understand the relevance of what you're saying.\n\nWas there any 'professioal environment' in this study? The AI judged a fragment of text without any environment, right?",
                                    "score": 2,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 05:11:03",
                                    "replies": [
                                        {
                                            "author": "Zoesan",
                                            "body": "It's kind of the same thing though. If I write in my dialect the way I speak with my friends, I will sound far less intelligent than if I write properly, the way I'd write a paper or an email to an important client.",
                                            "score": 6,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 05:13:23",
                                            "replies": [
                                                {
                                                    "author": "Salindurthas",
                                                    "body": ">I will sound far less intelligent\u00a0\n\nYes, many people are biased against AAE to assume it is actually Standard English with bad grammar, and hence perceive it as less intelligent.\n\nThe study seems to say that ai models reproduce that false perspection.\n\n---\n\n>if I write properly\n\nWhat do you mean by 'properly'? Do you think there is something improper about AAE?\n\n---\n\n>the way I'd write a paper or an email to an important client.\n\nDoes this bear any relevance to the study here? Is this comment on the speakers dreams a paper or important client?",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 05:28:51",
                                                    "replies": [
                                                        {
                                                            "author": "canteloupy",
                                                            "body": "People also perceive rural accents as dumber and it's unfair. But it's also based on statistics where historically, since universities are in cities, any rural person who gets in will lose their accent. Even more do because their accent will be made fun of. But they didn't get smarter, they had that potential and then socially blended in.\n\nAfricans also tend to lose their accent when seeking work in Europe. Same thing.\n\nIt's more absurd if you think of a Swiss engineer being thought of as stupider than a French engineer speaking the same language but with a Swiss accent and syntax in France, even though he went to a better engineering school. Yet that happens all the time.",
                                                            "score": 5,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 08:02:35",
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "Zoesan",
                                                            "body": " > The study seems to say that ai models reproduce that false perspection.\n\nIs it false though\n\n > What do you mean by 'properly'? Do you think there is something improper about AAE?\n\nWith proper grammar and yes, insofar as there is anything wrong with other non-written dialects.",
                                                            "score": 5,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 08:26:35",
                                                            "replies": [
                                                                {
                                                                    "author": "Salindurthas",
                                                                    "body": "So to you, AAE has inherently improper grammar? Or only when written?\n\nI think you are simply rejecting that it is an actual dialect if you say that.",
                                                                    "score": 0,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 08:39:32",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Zoesan",
                                                                            "body": "> AAE has inherently improper grammar? Or only when written?\n\nA little bit of the former, a lot of the latter.\n\nMoreover, I find people that are *unable* to switch out of dialects or *unwilling* to switch out of dialects to facilitate easier communication to be unintelligent, assholes, or both",
                                                                            "score": 7,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 08:44:15",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Salindurthas",
                                                                                    "body": "Well, I flatly disagree that AAE has improper grammar, written or not. What is imporper about it? It has just as cogent systems and internal rules of grammar as standard english.\n\n----\n\nYes if two people know the same dialect, and they don't choose to speak that shared dialect, then that may indeed be meanspirited or a poor decision. But that doesn't bare relevance to the test the study did, does it?",
                                                                                    "score": -2,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 09:10:16",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Zoesan",
                                                                                            "body": " > What is imporper about it?\n\nUhm. Do I need to point at a grammar textbook?\n\n > It has just as cogent systems and internal rules of grammar as standard english.\n\nIt does not",
                                                                                            "score": 1,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-03 03:06:01",
                                                                                            "replies": []
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "This is a very cool thing for people to know when trusting an LLM as \"impartial'. There are closed source AI models being used to determine reoffending rate in people being sentenced for a crime. Creepy.\n\n\nAlso: if you hadn't guessed they are racist. Not a big surprise.\u00a0",
            "score": 35,
            "depth": 0,
            "timestamp": "2024-09-02 01:31:06",
            "replies": [
                {
                    "author": "Zoesan",
                    "body": "Is it racist or is it accurate? Or is it both?",
                    "score": 16,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:01:29",
                    "replies": [
                        {
                            "author": "binary_agenda",
                            "body": "\"Racist\" really seems to depend on if the stereotype is considered flattering or not and who the party that put forth the stereotype is.\u00a0",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-03 11:47:07",
                            "replies": []
                        },
                        {
                            "author": "Drachasor",
                            "body": "It's racist and not accurate, because it just repeats existing racist decisions.\u00a0 AI systems to decide medical care have had the same problems where minorities get less care for the same conditions.",
                            "score": 17,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:49:07",
                            "replies": [
                                {
                                    "author": "A_Starving_Scientist",
                                    "body": "We need regulation for this. The clueless MBA's are using AI to make decisions about medical treatments and insurance claims, and act as if AIs are some sort of flawless arbiter.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 15:05:20",
                                    "replies": [
                                        {
                                            "author": "Drachasor",
                                            "body": "Technically, it's against the law.\u00a0 The difficulty with it is proving it.\u00a0 So I think what we need are laws and standards on proving they any such system is not biased before it can be sold or used instead of it being after the fact.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 16:21:19",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "Zoesan",
                                    "body": "Which part is inaccurate?",
                                    "score": -5,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 08:27:31",
                                    "replies": [
                                        {
                                            "author": "Drachasor",
                                            "body": "If you have trouble figuring out why judging someone based on their dialect is not valid then you've got a lot of work to do.\n\n\nDo you also not understand why it's not acceptable to give minorities substandard medical care just because an AI says to?",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:30:03",
                                            "replies": [
                                                {
                                                    "author": "Zoesan",
                                                    "body": " > If you have trouble figuring out why judging someone based on their dialect is not valid\n\nThat's not what your specific post said though, which I'm referring to with my question of accuracy.\n\nI'll ignore the asinine rest of your comment, but I do judge you to be less intelligent based off of it.",
                                                    "score": -13,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 08:36:00",
                                                    "replies": [
                                                        {
                                                            "author": "Drachasor",
                                                            "body": "I'm not following.\u00a0 Please tell me what part you think is accurate and be explicit.",
                                                            "score": 3,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 08:38:14",
                                                            "replies": [
                                                                {
                                                                    "author": "Zoesan",
                                                                    "body": "Is this some sort of cheap way of trying to weasel out?\n\nThis part \"There are closed source AI models being used to determine reoffending rate in people being sentenced for a crime.\"\n\nWas\n\nit\n\ninaccurate?",
                                                                    "score": -1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 08:42:03",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Drachasor",
                                                                            "body": "And I said they aren't.\u00a0 I even have an example in another field that has the same problem and I said why the problem exists.\n\n\n\nWhat part don't you understand?\u00a0 Do you for some reason require proof that systems we know will produce bigoted output based on bigoted input are doing that instead of demanding proof that they aren't?\u00a0 It's weid where you are putting the burden of proof here in an article about how AI systems are biased and all the other research showing other AI systems are biased too.\u00a0 And yes, that means they aren't accurate either.\u00a0\n\n\nWhy is this so hard for you to understand?",
                                                                            "score": 11,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 08:48:03",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Deleted",
                                                                                    "body": "[deleted]",
                                                                                    "score": 2,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 14:13:52",
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "Drachasor",
                                                                                            "body": "He was pretty clearly responding to a comment about using it to determine resentencing rates.\n\n  \nHere's what we know about how machine learning handles such tasks (not just LLMs!):  \n1.  We know that the training data will have racial bias in it.  There's a difference between how people get sentenced based on race, when all other factors are equal.  People aren't even necessarily aware they are doing it.  \n2.  The training model picks up on those differences and then copies them, continuing the inequality.  \n3.  If you exclude race from the training data, it still copies the racism in the system based on other identifiers that are strongly correlated such as names, where they live, etc, etc.  \n4.  It's very difficult to avoid this problem.   Race isn't the only bias either.  One possible way is to create all of the training data by hand to avoid any bias and have it be based on real data that then gets gone through by hand to create an entirely new set of data without these problems.  But this is very difficult and very expensive.  There doesn't seem to be a cheap way to do this.\n\nAnd of course, LLMs, based on the fact they need so much data, basically can't avoid this problem.  To get the very imperfect performance we see now, they are already basically trained on everything available.",
                                                                                            "score": 1,
                                                                                            "depth": 10,
                                                                                            "timestamp": "2024-09-02 20:13:41",
                                                                                            "replies": []
                                                                                        }
                                                                                    ]
                                                                                },
                                                                                {
                                                                                    "author": "Zoesan",
                                                                                    "body": "Really, no response to my other post?",
                                                                                    "score": 0,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-03 03:11:37",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "Deleted",
                                                    "body": ">judging someone based on their dialect is not valid\n\nDo you mean a negative judgement or any type of judgement? Because I don't see how that would be the case otherwise. You judge people on their clothing, their hair style, and so many other hundreds of aspects that are outwardly visible. If you took two people speaking English and one has a strong southern accent while another has a New York accent, of course you're going to make a few initial judgements.",
                                                    "score": 0,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 23:13:26",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "Deleted",
                            "body": "It's racist if the objective numbers and statistics give me frowny face",
                            "score": 2,
                            "depth": 2,
                            "timestamp": "2024-09-02 23:17:00",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "BringOutTheImp",
                    "body": "Is it accurate with its predictions though?",
                    "score": 3,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:32:14",
                    "replies": [
                        {
                            "author": "paxcoder",
                            "body": "Are you arguing for purely racial profiling? Would you want to be the \"exception\" that was condemned for being of a certain skin color?",
                            "score": 4,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:31:07",
                            "replies": [
                                {
                                    "author": "BringOutTheImp",
                                    "body": "Not arguing - just asking a simple question whether the AI was effective at doing what it was designed to do: to accurately predict recidivism.\n\nBut to answer your question - if the AI would accurately predict my behavior, I don't know what reason I would have to get mad at it.",
                                    "score": -3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 05:36:45",
                                    "replies": [
                                        {
                                            "author": "canteloupy",
                                            "body": "Well the problem is recidivism is judged based on conviction rates, which we all know has some racist bias.",
                                            "score": 8,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 07:50:31",
                                            "replies": [
                                                {
                                                    "author": "BringOutTheImp",
                                                    "body": "So the data returned by a computational machine designed to compute specific odds gives you the hard numbers you asked for, but you decide to disregard those numbers based on ideology.\n\nThat's pretty much how millions of people starved to death during the Great Leap Forward, because the numbers were ignored based on ideology.\n\nBut I'm sure this time it will be different.",
                                                    "score": 4,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 17:26:23",
                                                    "replies": [
                                                        {
                                                            "author": "Deleted",
                                                            "body": "We don't adhere to the truth on reddit, other than those truths that are most convenient",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 23:14:37",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "panenw",
                                    "body": "racial profiling is bad precisely because police officers will let their racial/political feelings bias their judgements towards the race. but to deem the factual association of race with crime as observed by AI as racist is irrational because they have no racial feelings\n\n  \nif the data is biased (or reflects privilege or something), that must be proven",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 22:36:17",
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "akko_7",
                            "body": "This isn't something people will let you discuss on reddit sadly, not with any actual honesty.",
                            "score": -2,
                            "depth": 2,
                            "timestamp": "2024-09-02 08:31:14",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "dannylew",
            "body": "I don't want to be dismissive of AI research. There is a new, contradictory post about AI's political leanings being posted here every day/week and it's all evidence that the current applications of LLMs need to be thrown out immediately. There's no world where we should be using a tool made from\u00a0Reddit and X (formerly Twitter).\u00a0",
            "score": 3,
            "depth": 0,
            "timestamp": "2024-09-02 09:17:14",
            "replies": []
        },
        {
            "author": "Check_This_1",
            "body": "It's just plain incorrect grammar",
            "score": 54,
            "depth": 0,
            "timestamp": "2024-09-02 00:36:16",
            "replies": [
                {
                    "author": "External-Tiger-393",
                    "body": "Dialectical variation and \"incorrect grammar\" are different things; and, even aside from that, language isn't prescriptive in most of the contexts where it's actually used. \n\nIt's really easy to call something incorrect when you're been taught that the only \"correct\" option is a form of English that you happen to already speak/use.",
                    "score": -13,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:57:48",
                    "replies": [
                        {
                            "author": "MaxParedes",
                            "body": "You\u2019re absolutely right about this, and actual linguists would agree. \u00a0 Dialectical variations of a language may have may have different levels of prestige, or different levels of acceptance in differing contexts, but that doesn\u2019t mean that the dialects are just plain incorrect grammar. \u00a0\n\nEdit, to be clear here I\u2019m not making the argument that all dialects should be treated equally. \u00a0It\u2019s useful to have a \u201cstandard\u201d language (even if what constitutes the standard will always be in flux and subject to debate). \u00a0 And it\u2019s inevitable that some dialects will have higher prestige than others in certain contexts.\u00a0\n\n\u00a0But as a matter of science, it\u2019s not right to say that dialect variants are simply incorrect grammar. \u00a0They are linguistic variants with their own coherent rules that have developed from (and/or have developed parallel to) what we consider to be the standard language.",
                            "score": 9,
                            "depth": 2,
                            "timestamp": "2024-09-02 10:42:38",
                            "replies": [
                                {
                                    "author": "External-Tiger-393",
                                    "body": "Oh, for sure. Having a standard dialect is really important in formal settings like academia and white collar work. I just don't think that it makes sense to judge people for using their own native dialects outside of those settings.",
                                    "score": 2,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 11:51:12",
                                    "replies": [
                                        {
                                            "author": "MaxParedes",
                                            "body": "I\u2019d say there\u2019s room for discussion about which settings are reasonable ones in which to expect use/mastery of standard English\u2014- but it\u2019s definitely not right to equate or associate dialect use with laziness, or with stupidity\u00a0",
                                            "score": 2,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 12:32:18",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "sentence-interruptio",
                            "body": "My younger self would have loved that simpler form of grammar. When I was learning English, I was so shocked to learn that the word 'be' mutates to 'am', 'are' or 'is' depending on what precedes it. I was like, \"I have to learn three more words for the same thing?\"",
                            "score": -17,
                            "depth": 2,
                            "timestamp": "2024-09-02 03:02:10",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "pseudopad",
                    "body": "Everyone today would be considered to have poor grammar by some old fart from the 1800s.",
                    "score": -22,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:46:34",
                    "replies": [
                        {
                            "author": "Check_This_1",
                            "body": "(this will offend people): Of course, you can talk however you like and ignore basic grammar rules while doing it, but then don't act surprised if people who value the use of proper grammar see you as less intelligent.",
                            "score": 49,
                            "depth": 2,
                            "timestamp": "2024-09-02 00:54:44",
                            "replies": [
                                {
                                    "author": "pseudopad",
                                    "body": "It's perfectly normal for a language as big and geographically widespread as English to have significant variations in vocabulary and grammar. That doesn't mean these groupings are less intelligent.",
                                    "score": -14,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:00:50",
                                    "replies": [
                                        {
                                            "author": "Check_This_1",
                                            "body": "I didn't say it does. It makes them sound less intelligent though. Please try to\u00a0understand the distinction.",
                                            "score": 29,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:22:19",
                                            "replies": [
                                                {
                                                    "author": "pseudopad",
                                                    "body": "So you agree that these incorrect assumptions should be removed from the language models, then?",
                                                    "score": -25,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:24:48",
                                                    "replies": [
                                                        {
                                                            "author": "Check_This_1",
                                                            "body": "Other than for national security purposes, I am generally against adding a lot of rules into LLMs because they will greatly restrict its capabilities long term.\u00a0",
                                                            "score": 19,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 01:51:34",
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "mrGeaRbOx",
                                                            "body": "So when confronted with a harsh complex reality your response is to repeat a simplistic hypothetical solution?\n\nI hope you never want career advancement beyond junior level.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 11:57:00",
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "Ciff_",
                                                    "body": "Only to the ignorant that is unaware of the different dialects.",
                                                    "score": -20,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:50:34",
                                                    "replies": []
                                                }
                                            ]
                                        },
                                        {
                                            "author": "Nerf_Me_Please",
                                            "body": "Grammar doesn't so wildly change from one region to another. Please show me a single school where they teach \"I be\" as a proper form of conjugation.",
                                            "score": 13,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:52:55",
                                            "replies": [
                                                {
                                                    "author": "-downtone_",
                                                    "body": "Not everyone imagined \"it be\" as a form of conjugation from thin air.  So, it was certainly learned.  I'd say, school of culture and social pressure.",
                                                    "score": -9,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 07:19:24",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "redditonlygetsworse",
                                    "body": "> (this will offend people)\n\nPeople will be (correctly) disagreeing with you not because they are offended, but because you are simply incorrect about how languages work.\n\n> proper grammar\n\nThere is no such thing; at least, not in the way that you are imagining it.",
                                    "score": -20,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:21:28",
                                    "replies": [
                                        {
                                            "author": "Check_This_1",
                                            "body": "When you learn English as a second language in school anywhere in the world, you're trained in proper grammar. Sure, language evolves, but saying \"there's no proper grammar\" dismisses the fact that grammar exists, and almost all books, news articles, and texts are written according to those rules.\u00a0\n\n\nJust be aware that others might interpret ignoring these rules as a sign of poor language skills.",
                                            "score": 32,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:41:03",
                                            "replies": []
                                        },
                                        {
                                            "author": "Consistent-Mastodon",
                                            "body": ">There is no such thing\n\nfr fr! teechers be seefing corectin my dialect. whose ful now, Mrs. Davidson?",
                                            "score": 16,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 02:43:03",
                                            "replies": []
                                        },
                                        {
                                            "author": "GentleTroubadour",
                                            "body": "Why even bother with the semicolon if; as you say; there is no such thing as proper grammar.",
                                            "score": 12,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:31:40",
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "plinocmene",
                                    "body": "Grammatical rules were invented by humans. It's not some fact out there where we can apply the methods of science and observe it and point and say \"see that's i before e except after c right there in the natural world.\"\n\nGrammatical rules have their purpose. Without them people can have a hard time understanding each other. So I'm not saying people shouldn't learn how to use grammatical rules. But I am saying that it doesn't make a person less intelligent if they are not practiced in doing so. It just reflects that they likely grew up in an environment where most people were using a different set of rules, and in that environment the intelligent thing to do if you want to be understood is to use those rules.\n\nIf you then find yourself in a different environment where people are using a different grammar even if you recognize that you'd benefit from switching to it it still takes time and practice to learn. It doesn't reflect a lack of intelligence any more than someone who grew up speaking a different language taking time to understand how to properly speak a new language reflects a lack of intelligence. If anything someone who grew up with one dialect and then learns another one will have exercised their brain and made it more powerful. Going back to their original dialect when talking with people who speak it doesn't subtract from that.",
                                    "score": -20,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:14:58",
                                    "replies": [
                                        {
                                            "author": "BringOutTheImp",
                                            "body": "There is a difference between intelligence and education. If you never learned proper grammar, then you are uneducated, but you can still be intelligent. Those two things aren't the same but they do often do go hand in hand, because intelligent people often seek out ways to educate themselves.",
                                            "score": 9,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 03:47:36",
                                            "replies": [
                                                {
                                                    "author": "plinocmene",
                                                    "body": "A lot of people know and speak different dialects. It's called code-switching. A person may know the standard rules but use the rules of the dialect they grew up with in certain contexts. A person overhearing them may wrongly assume they don't know the standard rules.\n\nEDIT: Here's another point. People, including myself who grew up with a dialect that is very close to standard have the privilege of being able to sound \"educated\" when all we did was just naturally pick up on the standard rules in childhood.",
                                                    "score": 3,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 13:39:55",
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Handzeep",
                                    "body": "Do I have to use British or American grammar rules then? Or should I clarify which English version I've used? I'd wish to not be viewed as less intelligent due to mistakingly using the wrong grammar. Bless you for making me aware of potentially making a mistake.",
                                    "score": -3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 07:26:52",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Happy-Viper",
            "body": "I mean, this is just \u201cincorrectly using English\u201d, \u201cI be so happy\u201d isn\u2019t correct, it is grammatically incorrect.",
            "score": 34,
            "depth": 0,
            "timestamp": "2024-09-02 03:07:49",
            "replies": [
                {
                    "author": "Drachasor",
                    "body": "That's not how language actually works and if you read it, you'd see that this bias didn't exist for Appalachian.",
                    "score": -5,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:50:16",
                    "replies": [
                        {
                            "author": "Deleted",
                            "body": "Ebonics was used a lot in older novels, very often (but not always) in a racially biased way, and it isn't frequently used now. Appalachian dialects don't show up nearly as often in writing.\n\nI'm guessing that this is where the discrepancy comes from, but I could be wrong.",
                            "score": 3,
                            "depth": 2,
                            "timestamp": "2024-09-02 08:09:06",
                            "replies": [
                                {
                                    "author": "Drachasor",
                                    "body": "I think one could make the case the racism towards certain dialects is much more common and a larger effect than classism towards dialects.",
                                    "score": 6,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 08:12:38",
                                    "replies": [
                                        {
                                            "author": "Deleted",
                                            "body": "I think it's important to note that in practice there's a lot of overlap between Appalachian, southern, and AAVE dialects. An author, however, is likely to make them completely distinct in order to make characterizations clear to the reader. Often this was done by using different phonetic spelling conventions for (roughly) similar pronunciations, and exaggerating the grammar for black characters. Examples of this can be found throughout Huckleberry Finn. \n\nI suspect that you're right about racial biases being stronger than class biases, particularly in the US where social class distinctions between economic classes are less pronounced. Studies like this can't explain the \"why\" though, so we can only speculate.",
                                            "score": 2,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:30:20",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "yallology",
                    "body": "It is indeed grammatical though. It\u2019s a well studied variant in linguistics. Look up the habitual be.",
                    "score": -1,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:45:09",
                    "replies": []
                }
            ]
        },
        {
            "author": "pruchel",
            "body": "You speak like that you'll be viewed as less intelligent by most people, because our collective experience has thought us it indicates you're less intelligent.\u00a0\nThis is what AI does, and why applying AI to any individual decision, like hiring, is still a bad idea.\n\n\nThat does not mean it's wrong, or racist, unless you use it for that exact purpose. And I'd argue in that case the person using it is the racist.\n\n\nCertainly, it's important to prune the erroneous misconceptions we as humans, and thus AI, have. At the same time I'd say it's just as important to highlight the biases and generalisations we make that _work_ and that are real and testable. Pretending they're not real is utterly inane.",
            "score": 19,
            "depth": 0,
            "timestamp": "2024-09-02 03:28:27",
            "replies": [
                {
                    "author": "canteloupy",
                    "body": "But this can also be because we have a narrow definition of intelligence which includes many racial and sociological biases.",
                    "score": 4,
                    "depth": 1,
                    "timestamp": "2024-09-02 08:05:45",
                    "replies": [
                        {
                            "author": "ribnag",
                            "body": "\"Ability to communicate\" is a critical skill in virtually any field.\n\nLet's be honest here, the movie stereotype of the nonverbal autistic mathematical genius is a scenario that *might* pop up once per generation.  The average Joe who doesn't even realize their grammar is atrocious, isn't that person.",
                            "score": 5,
                            "depth": 2,
                            "timestamp": "2024-09-02 15:27:46",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "sheofthetrees",
            "body": "people think AI is actually smart. it just spits out what it's fed according to probability.",
            "score": 11,
            "depth": 0,
            "timestamp": "2024-09-02 03:29:23",
            "replies": [
                {
                    "author": "2eggs1stone",
                    "body": "Today I learned that I'm an AI",
                    "score": 3,
                    "depth": 1,
                    "timestamp": "2024-09-02 07:17:35",
                    "replies": []
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "[removed]",
            "score": 10,
            "depth": 0,
            "timestamp": "2024-09-02 01:51:39",
            "replies": []
        },
        {
            "author": "dynorphin",
            "body": "It's interesting that they chose not to publish their paper in AAVE.",
            "score": 17,
            "depth": 0,
            "timestamp": "2024-09-02 03:21:29",
            "replies": []
        },
        {
            "author": "_meaty_ochre_",
            "body": "Wow I guess they\u2019re running out of nonsense to fearmonger about. GPT models are heavily tuned towards \u201cprofessional assistant\u201d interactions. Aside from maybe \u201caggressive\u201d, all of those words are just accurate descriptions of someone that would use nonstandard English in the equivalent of a work email.",
            "score": 8,
            "depth": 0,
            "timestamp": "2024-09-02 02:55:26",
            "replies": [
                {
                    "author": "Drachasor",
                    "body": "Except they compared it to Appalachian English and didn't get that result.\n\n\nEven OpenAI admits that they can't get rid of racism and sexism in the model.\u00a0 They should not be used to make decisions about people or that affect people.",
                    "score": 8,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:47:01",
                    "replies": [
                        {
                            "author": "_meaty_ochre_",
                            "body": ">Stereotype strength for AAE, Appalachian English (AE), and Indian English (IE). Error bars represent the standard error around the mean across different language models/model versions and prompts (n = 90). AAE evokes the stereotypes significantly more strongly than either Appalachian English or Indian English. ***We only conduct this experiment with GPT2, RoBERTa, and T5.***\n\nIt very much stands out that they only ran it on the three weakest, oldest models and excluded any results from GPT3.5 and GPT4. Earlier in the paper, these models were also *overtly* racist. I\u2019d bet any amount of money that the AE/AAVE/IE differences all but disappear in models that aren\u2019t multiple years old.\n\nThere are several parts of the paper where they exclude the more recent models without explanation. They\u2019re intentionally using old, irrelevant models known to be racist to get the moral panic results they want to publish. It\u2019s reprehensible behavior that should not have passed peer review.",
                            "score": 3,
                            "depth": 2,
                            "timestamp": "2024-09-02 12:13:35",
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "YourphobiaMyfetish",
                    "body": ">all of those words are just accurate descriptions of someone that would use nonstandard English in the equivalent of a work email.\n\nLazy, stupid, and dirty? You're just racist. Get fucked.",
                    "score": -7,
                    "depth": 1,
                    "timestamp": "2024-09-02 04:52:48",
                    "replies": [
                        {
                            "author": "Zoesan",
                            "body": "Sorry, but if you cannot resort to correct written english in a professional environment, then it's not racist to be overlooked.",
                            "score": 9,
                            "depth": 2,
                            "timestamp": "2024-09-02 05:05:58",
                            "replies": [
                                {
                                    "author": "2Fast2Real",
                                    "body": "English is a construct. What people call \u201ccorrect\u201d is subjective. It\u2019s racist to blanketly refer to the way different cultures speak as \u201cincorrect\u201d and \u201cunprofessional\u201d.",
                                    "score": -9,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 05:35:01",
                                    "replies": [
                                        {
                                            "author": "mrGeaRbOx",
                                            "body": "My technical writing professor would laugh at this claim.",
                                            "score": 3,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 12:01:56",
                                            "replies": []
                                        },
                                        {
                                            "author": "Deleted",
                                            "body": "There's no singular \"correct\" way to speak or write, but if people don't speak and write using the same conventions it's hard to understand each other. Over time we developed standard conventions for spelling and grammar, so that there would be a single correct way to speak in formal and professional settings to prevent misunderstandings. Different accents are fine, different grammar is accepted to a point, different spelling is not. Using \"cuh\" instead of \"because\" like in this study is both unprofessional and incorrect, especially in an email. \n\nThis has nothing to do with race, it's expected of everyone. Also, race and culture are not the same thing.",
                                            "score": 3,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 07:48:02",
                                            "replies": []
                                        },
                                        {
                                            "author": "Zoesan",
                                            "body": "hurr durr everything is a construct shut up",
                                            "score": 3,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 08:26:48",
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "TheFabiocool",
            "body": "I find this study is perpetuating the issue because it's using plain English instead of \"on God, it do be like that\"",
            "score": 6,
            "depth": 0,
            "timestamp": "2024-09-02 04:30:38",
            "replies": [
                {
                    "author": "Academic_Storm6976",
                    "body": "This and there's dozens or hundreds of distinct local dialects compared to the relatively narrow range of \"proper English.\"\n\n\nIf you speak in a local dialect, on average, you care less\u00a0about communicating effectively to most people as long as \"your people\" can understand you.\u00a0\n\n\nYou've indicated that you care less if visitors/immigrants from other countries can accurately understand you or even people from different places that are English natives.\u00a0\n\n\n\nIt's no wonder AI has this bias.\u00a0",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 10:35:19",
                    "replies": []
                }
            ]
        },
        {
            "author": "shakamaboom",
            "body": "just like real people, the data its trained on. who woulda thunk?",
            "score": 6,
            "depth": 0,
            "timestamp": "2024-09-02 01:10:40",
            "replies": []
        },
        {
            "author": "seclifered",
            "body": "It\u2019s impossible to get unbiased developers or training data, so the resulting ai will be biased too. For example, if I say \u201cbanana\u201d, most of us would think of the yellow ones, but an unbiased answer would include blue and red bananas. Most people don\u2019t even know such colored bananas exist, hence bias is introduced",
            "score": 3,
            "depth": 0,
            "timestamp": "2024-09-02 01:57:47",
            "replies": []
        },
        {
            "author": "canteloupy",
            "body": "I believe that some people are actively against code-switching to avoid perpetuating such biases but the problem with that is that it's game theory applied to professional opportunities.\n\nWomen who became engineers in the 80s describe having to dress less feminine for similar reasons, and that it became easier in the 2000s.",
            "score": 2,
            "depth": 0,
            "timestamp": "2024-09-02 08:11:00",
            "replies": [
                {
                    "author": "Deleted",
                    "body": "[deleted]",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 09:55:06",
                    "replies": [
                        {
                            "author": "canteloupy",
                            "body": "That isn't all that it is, though. It's more than just trying to be understood. It's being accepted.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-02 09:57:55",
                            "replies": [
                                {
                                    "author": "Deleted",
                                    "body": "[deleted]",
                                    "score": 1,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 10:08:12",
                                    "replies": [
                                        {
                                            "author": "canteloupy",
                                            "body": "Again, your understanding of code switching is very narrow. It includes a lot more than just efforts to be understood. Everyone understands \"yall\" for example, but the connotation of using that word in Upper East Side bankers' clubs is different.",
                                            "score": 1,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 10:32:05",
                                            "replies": [
                                                {
                                                    "author": "Deleted",
                                                    "body": "[deleted]",
                                                    "score": 1,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 11:29:59",
                                                    "replies": [
                                                        {
                                                            "author": "canteloupy",
                                                            "body": "Your explanation makes it seem like you are contorting to justify negative biases based on superficial criteria, as if the dominant classes have every right to judge the others and gatekeep based on some pop science interpretation of interpersonal relationships and discounting power dynamics at play.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 11:36:29",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "But... [https://www.reddit.com/r/science/comments/1f6rfck/large\\_language\\_models\\_appear\\_to\\_be\\_more\\_liberal\\_a/](https://www.reddit.com/r/science/comments/1f6rfck/large_language_models_appear_to_be_more_liberal_a/)",
            "score": 4,
            "depth": 0,
            "timestamp": "2024-09-02 00:36:43",
            "replies": [
                {
                    "author": "ContraryConman",
                    "body": "They speak like inoffensive liberals because it is safer for companies to program them to do so but have all the implicit bias problems of society at large",
                    "score": 14,
                    "depth": 1,
                    "timestamp": "2024-09-02 00:47:26",
                    "replies": []
                }
            ]
        },
        {
            "author": "YsoL8",
            "body": "I feel like we are in danger of people concluding racism is somehow inherent and heres the proof",
            "score": 2,
            "depth": 0,
            "timestamp": "2024-09-02 02:49:56",
            "replies": []
        },
        {
            "author": "Deleted",
            "body": "Train data on biased people =",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 08:30:43",
            "replies": []
        },
        {
            "author": "PerpetwoMotion",
            "body": "ChatGPT has the same ghastly grammar that Americans use-- yeah! we noticed! Crap in = crap out",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 09:24:03",
            "replies": []
        },
        {
            "author": "Jfunkyfonk",
            "body": "Well. Good thing that Axon, the company that makes policing equipment in the US, is starting to toll out AI in their products. Meanwhile, most people are still having a moral panic about its use in schools.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 09:49:21",
            "replies": []
        },
        {
            "author": "I-Am-Baytor",
            "body": "So this AI is a grade school teacher?",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 10:42:52",
            "replies": []
        },
        {
            "author": "Thatotherguy129",
            "body": "We hear this over and over, but has anyone actually seen it? As in, is there a clear-cut example of an AI doing something racist? It's not that I don't believe it (in fact, it's kind of expected), but I'm interested in *seeing it, not *hearing it.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 13:10:13",
            "replies": []
        },
        {
            "author": "vorilant",
            "body": "How do they define a bias though? It's a very popular buzzword that guarantees funding and agreement . But does it mean anything important?",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 13:13:11",
            "replies": []
        },
        {
            "author": "A_Starving_Scientist",
            "body": "If the training data is biased, the model will be biased. Try to manually sanitize the data? You end up with multicultural nazis like Google did. It is actually a very difficult problem as input data that is free of biases is not actually possible as you'd first have to define what free of bias even is.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 14:59:37",
            "replies": []
        },
        {
            "author": "Deleted",
            "body": "There's loads of people who write like that regardless of race, maybe a higher portion of African Americans write but I'm sure they'll find correlates to these associations when race is controlled.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 17:55:03",
            "replies": []
        },
        {
            "author": "Selky",
            "body": "Crazy that this is being called racism when it\u2019s just responding to data. Even LLMs can\u2019t escape this nonsense.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-03 00:05:25",
            "replies": []
        },
        {
            "author": "CosmicLovecraft",
            "body": "AI has been 'racist' in every way possible since first tests and alpha models begun. Actually the majority of 'allignment' is trying to instil blank slatism and eliminate HBD from it's logic.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-03 02:27:53",
            "replies": []
        },
        {
            "author": "pinkknip",
            "body": "When the question is itself worded in a  bias way how can the results produce anything other than showing people are bias? You have five words to choose from, none of them are what came to mind when I read either sentence. Both sentences were talking about waking from dreams, and they are \"too real\" which I inferred to mean they have woken from a nightmare. My words of choice were scared and stress. When I first saw the answers to choose from I thought, \"English as a second language\" person prepared the questions. I guess I was right, because the first language of AI is code.  Another thought was, that the green speaker was older and the blue speaker was probably younger than 23. I also think, that the question set up as it is presented also doesn't do the model any favors by looking a lot like I'm reading text messages. I make no judgement from text messages because if someone is texting me chances are great I already know a bit about them so won't be making any of the five assumptions that are listed.  Finally, both sentences have syntax grammar errors so upon seeing that they have used words like brilliant and intelligent, I started thinking are they testing for something else in this experiment beside what they told me they were testing for? I know from compulsory participation is psychology experiments when one was taking psychology classes that telling test subjects they are studying one thing when they were studying something else is a common tactic.  \n\nIt goes to show you how little AI understands humans.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-03 06:14:57",
            "replies": []
        },
        {
            "author": "StephanXX",
            "body": "Racism is a social construct. LLMs aren't social, they're not conscious, they're just glorified if/then statements. \n\nThis is a deeply unscientific claim.",
            "score": -17,
            "depth": 0,
            "timestamp": "2024-09-02 01:03:41",
            "replies": [
                {
                    "author": "Ciff_",
                    "body": "> they're just glorified if/then statements\n\nNo, they are layers of nodes all with literal biases coded into them as weights based on their training data - which in LLMs comes from texts written by humans. It basicly has all racism in written recorded history built into the weighting of its neural net. Now you can be selective about the training data, but that will then be bound by the bias of the human selecting the data.",
                    "score": 13,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:40:14",
                    "replies": []
                },
                {
                    "author": "PotsAndPandas",
                    "body": "LLMs are fed data originating from social creatures though, hence the issue here.",
                    "score": 15,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:20:11",
                    "replies": [
                        {
                            "author": "StephanXX",
                            "body": "If a computer is instructed to emit racist statements, it will emit racist statements. The flaw isn't with \"AI\", it's with the operators who feed it racism. Obviously such headlines wouldn't be scientific or newsworthy. The claim is still deeply unscientific.",
                            "score": -20,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:23:58",
                            "replies": [
                                {
                                    "author": "PotsAndPandas",
                                    "body": "Okay real quick, can you describe how LLMs are/could be made in your view that excludes all possible sources of racism?",
                                    "score": 9,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:41:46",
                                    "replies": [
                                        {
                                            "author": "Deleted",
                                            "body": "[deleted]",
                                            "score": 0,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:54:02",
                                            "replies": [
                                                {
                                                    "author": "Ciff_",
                                                    "body": "You get the same problem. The LLM you use to select/analyze the training data, what data will that one have been trained on?",
                                                    "score": 5,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:55:37",
                                                    "replies": [
                                                        {
                                                            "author": "Deleted",
                                                            "body": "[deleted]",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 01:58:33",
                                                            "replies": [
                                                                {
                                                                    "author": "Ciff_",
                                                                    "body": "How so? Humans will have decided the training data for the LLM determining what is racism. How do you not get in practice the same thing? It is still humans deciding what is racism.",
                                                                    "score": 1,
                                                                    "depth": 7,
                                                                    "timestamp": "2024-09-02 01:59:54",
                                                                    "replies": [
                                                                        {
                                                                            "author": "Deleted",
                                                                            "body": "[deleted]",
                                                                            "score": 1,
                                                                            "depth": 8,
                                                                            "timestamp": "2024-09-02 02:03:37",
                                                                            "replies": [
                                                                                {
                                                                                    "author": "Ciff_",
                                                                                    "body": "Maybe so but how is that relevant? It not change the fact that it reflects human bias. It does not matter how many layers of trained LLMs you run, in the end humans have selected the data (and you won't have millions of humans selecting the data).\n\nYour option is either to use \"all\" data (such as the racist LLMs described in the article), OR have a few human \"experts\" select specific data. Neither is optimal. Both has bias.",
                                                                                    "score": 2,
                                                                                    "depth": 9,
                                                                                    "timestamp": "2024-09-02 02:08:46",
                                                                                    "replies": []
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "OkayShill",
                    "body": ">This is a deeply unscientific claim.\n\nThis can be said about your perspective as well.",
                    "score": 9,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:23:20",
                    "replies": []
                },
                {
                    "author": "Drachasor",
                    "body": "If you think computer system can't make racist decisions then you're being ridiculous.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:53:31",
                    "replies": []
                },
                {
                    "author": "2eggs1stone",
                    "body": "LLMs are not glorified if/then statements.  In fact there is not a single if/then statement within source of an LLM. You absolutely could train an LLM to output racist text.  I'd argue that the example above is not racism and you can read my previous comment on that argument.",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 07:16:21",
                    "replies": []
                }
            ]
        },
        {
            "author": "Deleted",
            "body": "LLM\u2019s are also left leaning",
            "score": 0,
            "depth": 0,
            "timestamp": "2024-09-02 01:31:55",
            "replies": []
        },
        {
            "author": "koiRitwikHai",
            "body": "yes there are inherently encoded biases in such models but that is primarily due to bias in the real life data \n\nchange society, change data, and AI models will change accordingly",
            "score": 2,
            "depth": 0,
            "timestamp": "2024-09-02 03:17:03",
            "replies": []
        },
        {
            "author": "Deleted",
            "body": "I make essentially the same calculation when I hear a deep southern drawl.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 08:41:15",
            "replies": []
        },
        {
            "author": "mad-grads",
            "body": "Well if you decide to speak in broken English and a logical judgment is being made about you, how is that a problem? If you speak like an idiot, and thus assumed to be an idiot; there\u2019s a simple antidote.. speak properly.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 09:04:06",
            "replies": []
        },
        {
            "author": "One_Horse_Sized_Duck",
            "body": "garbage in garbage out.",
            "score": 1,
            "depth": 0,
            "timestamp": "2024-09-02 09:42:58",
            "replies": []
        },
        {
            "author": "Rocky_Vigoda",
            "body": "All the 'AI' is doing is shining a light on systemic racism in US academia.\n\n> The slums are the handiwork of a vicious system of the white society; Negroes live in them but do not make them any more than a prisoner makes a prison. - MLK\n\nAmericans were supposed to end racism in the 60s by ending segregation, integrating, and getting rid of stupid racist labels like black or white.\n\nThe US started to integrate after MLK was murdered but stopped in the late 80s/early 90s when US media and social academics imposed the new African-American label and told everyone that it was cultural for them to live in the ghetto and use Jive or Ebonics which was renamed as AAVE.\n\nSystemically, racism is imposed top down through your guys' media, schools, politics. Your upper class knows that 12% 'black' demographic is a socio-economic influencer for the roughly 65% 'white' majority so they don't want Americans to integrate.\n\nPersonally this is sort of funny. You guys are like 'the AI is racist'. No, no it's not. It's your system that is racist and designed to keep 'black' people in the ghetto and below their worth as individuals.",
            "score": -2,
            "depth": 0,
            "timestamp": "2024-09-02 05:04:55",
            "replies": [
                {
                    "author": "Drachasor",
                    "body": "The AI is racist because the training data is racist which is because racism is still a major problem.\u00a0 All these things are true.",
                    "score": 1,
                    "depth": 1,
                    "timestamp": "2024-09-02 05:54:19",
                    "replies": [
                        {
                            "author": "Rocky_Vigoda",
                            "body": "Yeah, because the US never integrated.",
                            "score": 1,
                            "depth": 2,
                            "timestamp": "2024-09-02 06:04:25",
                            "replies": [
                                {
                                    "author": "Drachasor",
                                    "body": "I don't disagree.\u00a0 I'm just saying it's accurate to say the AI is racist too, for that reason.\u00a0 Hmm, it's also worth noting that the can't get rid of the racism in the model either -- they've tried.\n\n\n\nAnd going by some of the comments, we have a long way to go (though we knew that already).",
                                    "score": 2,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 08:09:23",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "bpeden99",
            "body": "I don't understand the innocent purpose of this?",
            "score": -1,
            "depth": 0,
            "timestamp": "2024-09-02 00:47:43",
            "replies": [
                {
                    "author": "kekkres",
                    "body": "there is no purpous, thats not how these programs are made, they are made by feeding it massive quantities of matirial and extrapolating patterns from that matirial, if the matiral has biases, than the model will have biases and there is no way to get a sufficiant quantitiy of matirial without those biases",
                    "score": 13,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:02:32",
                    "replies": [
                        {
                            "author": "bpeden99",
                            "body": "Forgive my ignorance, but \"you need bias to train against bias?\" I'm sure I simplified it, but is that the jist",
                            "score": 3,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:07:27",
                            "replies": [
                                {
                                    "author": "k4ndlej4ck",
                                    "body": "It's judging by spelling and grammar, race has just been thrown in for clicks.\n\n  \nUnless you operate under the assumption that minorities are illiterate.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:18:16",
                                    "replies": [
                                        {
                                            "author": "bpeden99",
                                            "body": "Is this operating under the assumption that minorities are illiterate?",
                                            "score": 4,
                                            "depth": 4,
                                            "timestamp": "2024-09-02 01:20:23",
                                            "replies": [
                                                {
                                                    "author": "k4ndlej4ck",
                                                    "body": "It never directly says so, but to me it comes across as being written by someone who thinks that, or wants the reader to assume that's what people think.\n\nThe article refers to incorrect spelling as minority dialect instead of say another language, and even admits it's the first to make this connection, and finishes by saying it has no answer.",
                                                    "score": 0,
                                                    "depth": 5,
                                                    "timestamp": "2024-09-02 01:29:03",
                                                    "replies": [
                                                        {
                                                            "author": "bpeden99",
                                                            "body": "That's so true... It's just not reliable for an opinion based on data.",
                                                            "score": 1,
                                                            "depth": 6,
                                                            "timestamp": "2024-09-02 01:31:47",
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "Catch11",
                            "body": "Yes but you are assuming that this model has succesfully predicted outcomes",
                            "score": 0,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:30:30",
                            "replies": [
                                {
                                    "author": "bpeden99",
                                    "body": "Not successfully",
                                    "score": 0,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:34:32",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "MemberOfInternet1",
            "body": "Of course it tries to generalize you, just like everything else. So that they can offer you the best possible service! And collect lots of data...\n\nAn AI can make a more fine-tuned generalization of you compared to when just some random website collects your data. It is because of the AI's language skills, and you talk directly to it.",
            "score": -1,
            "depth": 0,
            "timestamp": "2024-09-02 03:04:28",
            "replies": [
                {
                    "author": "nicuramar",
                    "body": "LLMs don\u2019t \u201ccollect lots of data\u201d.",
                    "score": 0,
                    "depth": 1,
                    "timestamp": "2024-09-02 03:26:45",
                    "replies": [
                        {
                            "author": "MemberOfInternet1",
                            "body": "Of course they collect data. It is literally what this thread is about. The AI define your personal characteristics, as in the topic, based on the data it has collected on you.\n\nWhether or not they sell the data is another story, but it definitely collects it.",
                            "score": -1,
                            "depth": 2,
                            "timestamp": "2024-09-02 03:51:58",
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "BrtFrkwr",
            "body": "AI doesn't generate anything by itself. It relies on algorithms supplied by a programmer and will reflect that person's prejudices.\n\nEdit: Heresy, isn't it? Sometimes there's more truth in the heresy than in the dogma.",
            "score": -23,
            "depth": 0,
            "timestamp": "2024-09-02 00:37:58",
            "replies": [
                {
                    "author": "Deleted",
                    "body": "[deleted]",
                    "score": 19,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:04:19",
                    "replies": []
                },
                {
                    "author": "CronoDAS",
                    "body": "Or prejudices that affected the data used to train it.",
                    "score": 15,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:01:12",
                    "replies": []
                },
                {
                    "author": "OkayShill",
                    "body": ">AI doesn't generate anything by itself. It relies on algorithms supplied by a programmer and will reflect that person's prejudices.\n\nNo, this is not how LLMs work.",
                    "score": 6,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:24:03",
                    "replies": [
                        {
                            "author": "BrtFrkwr",
                            "body": "Sometimes there is more truth in the heresy than the dogma.",
                            "score": -9,
                            "depth": 2,
                            "timestamp": "2024-09-02 01:33:49",
                            "replies": [
                                {
                                    "author": "Ciff_",
                                    "body": "Speak plainly or remain the fool.",
                                    "score": 3,
                                    "depth": 3,
                                    "timestamp": "2024-09-02 01:51:42",
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "foundafreeusername",
                    "body": "Our modern AI learns from data and isn't hard coded. e.g. the data might come from reddit posts and as such it gets the same bias as the humans generating the data",
                    "score": 4,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:04:21",
                    "replies": []
                },
                {
                    "author": "WoolPhragmAlpha",
                    "body": "Modern AI isn't programmed, it is trained. The training data is still subject to bias, but it's not like there's a big chain of if/else logic where an individual programmer can discreetly insert a biased decision.\n\nEdit after seeing your edit: \n\nIt's not \"heresy\", it just completely misunderstands how current AI is built.",
                    "score": 6,
                    "depth": 1,
                    "timestamp": "2024-09-02 01:05:11",
                    "replies": []
                }
            ]
        },
        {
            "author": "nanosam",
            "body": "AI that generates racist decisions = training data contained racist bias\n\nPeople need to remember that AI is not really intelligent, it is a machine learning algorithm that uses pattern recognition based on training data\n\nIf training data has racist biases - so will the output",
            "score": 0,
            "depth": 0,
            "timestamp": "2024-09-02 08:37:53",
            "replies": []
        },
        {
            "author": "Twootwootwoo",
            "body": "One day they tell me (literally yesterday) that AI is left-wing and the other that it's racist. Anyway, this basically proves it's the subject of various biases depending on exposure and that it can't callibrate itself not even to the desired place their creators want outside of specific questions or issues that might be predetermined such as asking Elon's one about him and those things, you prolly know what i'm talking about.",
            "score": -1,
            "depth": 0,
            "timestamp": "2024-09-02 07:36:51",
            "replies": []
        }
    ]
}